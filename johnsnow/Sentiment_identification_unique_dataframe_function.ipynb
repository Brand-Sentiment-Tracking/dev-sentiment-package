{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/python-package/blob/main/johnsnow/Sentiment_identification_unique_dataframe_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYgZXG4gDt1"
      },
      "source": [
        "# **Class for Sentiment Analysis for News Articles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDySD2IHU9di",
        "outputId": "07aee23e-cc25-4c02-b680-dbf35b69ad75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 57 kB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 44.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 50.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOW8Mt7VH97",
        "outputId": "0477ab84-9f3c-4868-e698-06f0a5700d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.1\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "# spark = sparknlp.start(gpu=False)\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a News Article"
      ],
      "metadata": {
        "id": "BDijGosdPGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = [ # two strings - headline & article body\n",
        "\"\"\"Google sued in US over 'deceptive' location tracking\"\"\", # headline\n",
        "\"\"\"Google is being sued in the US over accusations it deceived people about how to control location tracking.\n",
        "\n",
        "The legal action refers to a widely reported 2018 revelation turning off one location-tracking setting in its apps was insufficient to fully disable the feature.\n",
        "\n",
        "It accuses Google of using so-called dark patterns, marketing techniques that deliberately confuse.\n",
        "\n",
        "Google said the claims were inaccurate and outdated.\n",
        "\n",
        "'Unfair practices'\n",
        "The legal action was filed in the District of Columbia. Similar ones were also filed in Texas, Indiana and Washington state.\n",
        "\n",
        "It refers to an Associated Press revelation turning off Location History when using Google Maps or Search was insufficient - as a separate setting, Web and App Activity, continued to log location and other personal data.\n",
        "\n",
        "The study, with researchers at Princeton University, found up to two billion Android and Apple devices could be affected.\n",
        "\n",
        "\"Google has relied on, and continues to rely on, deceptive and unfair practices that make it difficult for users to decline location tracking or to evaluate the data collection and processing to which they are purportedly consenting,\" the legal action alleges.\n",
        "\n",
        "'Robust controls'\n",
        "Google told BBC News the case was based \"on inaccurate claims and outdated assertions about our settings\".\n",
        "\n",
        "A representative added: \"We have always built privacy features into our products and provided robust controls for location data.\n",
        "\n",
        "\"We will vigorously defend ourselves and set the record straight.\"\n",
        "\n",
        "Visual misdirection\n",
        "The legal action claims Google's policies contained other \"misleading, ambiguous and incomplete descriptions... but guarantee that consumers will not understand when their location is collected and retained by Google or for what purposes\".\n",
        "\n",
        "It refers to dark patterns, design choices that alter users' decision-making for the designer's benefit - such as, complicated navigation menus, visual misdirection, confusing wording and repeated nudging towards a particular outcome.\n",
        "\n",
        "Data regulators are increasingly focusing on these practices.\n",
        "\n",
        "Google faces a raft of other legal actions in the US, including:\n",
        "\n",
        "In May 2020, Arizona filed a legal action over the same issue\n",
        "In December 2020, multiple US states sued over the price and process of advertising auctions\n",
        "In October 2020, the US Justice Department alleged Google had a monopoly over search and search advertising\"\"\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "kzD5yHCBTfKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Brand Identification Class"
      ],
      "metadata": {
        "id": "rmq_-RXkbB1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def create_ranked_result_df(self, text):\n",
        "        # Run the pipeline for the text\n",
        "        text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index = [0]))\n",
        "        result = self.pipeline_model.transform(text_df)\n",
        "        \n",
        "        # Tabulate results\n",
        "        df = result.select(F.explode(F.arrays_zip('document.result', 'ner_chunk.result',\"ner_chunk.metadata\")).alias(\"cols\")).select(\\\n",
        "        F.expr(\"cols['1']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['2'].entity\").alias('result'))\n",
        "        \n",
        "        # Rank the identified ORGs by frequencies\n",
        "        ranked_df = df.filter(df.result == 'ORG').groupBy(df.chunk).count().orderBy('count', ascending=False)\n",
        "\n",
        "        return ranked_df\n",
        "\n",
        "\n",
        "    def predict_by_headline(self, headline):\n",
        "        ranked_df_hl = self.create_ranked_result_df(headline)\n",
        "        # ranked_df_hl.show(100, truncate=False)\n",
        "        \n",
        "        # If no ORG identified in headline, return None\n",
        "        if ranked_df_hl.count() == 0:\n",
        "            return None\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif ranked_df_hl.count() == 1:\n",
        "            return ranked_df_hl.first()[0]\n",
        "        # If one ORG appear more than the others, return the first one \n",
        "        elif ranked_df_hl.first()[1] > ranked_df_hl.collect()[1][1]:\n",
        "            return ranked_df_hl.first()[0] \n",
        "        else: # If multiple ORGs appear the same time, leave decision to article body (TO BE MODIFIED)\n",
        "            return None\n",
        "\n",
        "\n",
        "    def predict(self, headline, body):\n",
        "        ranked_df = self.create_ranked_result_df(body)\n",
        "\n",
        "        # Return the ORG with highest freq (at least >= 2)\n",
        "        if ranked_df.first()[1] >= 2: \n",
        "            return ranked_df.first()[0] \n",
        "        else:\n",
        "            return None\n",
        "        # TO DO: break even - Wikidata#"
      ],
      "metadata": {
        "id": "5JQeWnV1a8Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Senitment Identification Class"
      ],
      "metadata": {
        "id": "-5m65UosNdY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "          # Create a custom pipline if requested\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "            document_assembler = DocumentAssembler() \\\n",
        "                .setInputCol('text') \\\n",
        "                .setOutputCol('document')\n",
        "\n",
        "            tokenizer = Tokenizer() \\\n",
        "                .setInputCols(['document']) \\\n",
        "                .setOutputCol('token')\n",
        "\n",
        "            sequenceClassifier = BertForSequenceClassification \\\n",
        "                  .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                  .setInputCols(['token', 'document']) \\\n",
        "                  .setOutputCol('class') \\\n",
        "                  .setCaseSensitive(True) \\\n",
        "                  .setMaxSentenceLength(512)\n",
        "\n",
        "            pipeline = Pipeline(stages=[\n",
        "                document_assembler,\n",
        "                tokenizer,\n",
        "                sequenceClassifier\n",
        "            ])\n",
        "\n",
        "            self.pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))\n",
        "\n",
        "        else:\n",
        "            self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "    def predict_string_list(self, string_list):\n",
        "        \"\"\"Predicts sentiment of the input list of strings.\n",
        "\n",
        "        Args:\n",
        "          string_list: List of strings to classify.\n",
        "        \"\"\"\n",
        " \n",
        "        # Annotate input text using pretrained model\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "            pipeline_annotator = LightPipeline(self.pipeline_model) # Convert the pipeline to an annotator\n",
        "        else:\n",
        "            pipeline_annotator = self.pipeline_model\n",
        "\n",
        "        annotations =  pipeline_annotator.annotate(string_list)\n",
        "\n",
        "        return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "\n",
        "\n",
        "    def predict_dataframe(self, df):\n",
        "        \"\"\"Annotates the input dataframe with the classification results.\n",
        "\n",
        "        Args:\n",
        "          df : Pandas or Spark dataframe to classify (must contain a \"text\" column)\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(df, pd.DataFrame):\n",
        "            # Convert to spark dataframe for faster prediction\n",
        "            df_spark = spark.createDataFrame(df) \n",
        "        else:\n",
        "            df_spark = df\n",
        "\n",
        "        # Annotate dataframe with classification results\n",
        "        df_spark = self.pipeline_model.transform(df_spark)\n",
        "\n",
        "        #Extract sentiment score\n",
        "        df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                            col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                            col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "\n",
        "        # Extract only target and label columns\n",
        "        df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "        # Rename to result column to Predicted Sentiment\n",
        "        df_spark = df_spark.withColumnRenamed(\"result\", \"Predicted_Sentiment\")\n",
        "\n",
        "        # Convert sentiment from a list to a string\n",
        "        df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "        # Join the predictions dataframe to the scores dataframe\n",
        "        # Add temporary column index to join\n",
        "        w = Window.orderBy(monotonically_increasing_id())\n",
        "        df_spark_with_index =  df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "        df_spark_scores_with_index =  df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "        # Join the predictions and the scores in one dataframe\n",
        "        df_spark_with_index = df_spark_with_index.join(df_spark_scores_with_index,\n",
        "                                df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "                                'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "        # Remove the index column\n",
        "        df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "        # Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "        df_pandas_postprocessed = df_spark_combined.toPandas()\n",
        "\n",
        "        return df_pandas_postprocessed\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, df_pandas_postprocessed):\n",
        "        \"\"\"Computes accuracy by comparing labels of input dataframe.\n",
        "\n",
        "        Args:\n",
        "          df_pandas_postprocessed: pandas dataframe containing \"True_Sentiment\" and \"Predicted_Sentiment\" columns\n",
        "        \"\"\"\n",
        "    \n",
        "        from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "        # Compute the accuracy\n",
        "        accuracy = accuracy_score(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "        accuracy *= 100\n",
        "        classification_report = classification_report(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "\n",
        "        # Alternatively if the input is a postprocessed spark dataframe\n",
        "        # Compute accuracy by comparing each true label with predicted label\n",
        "        # accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "\n",
        "        return accuracy, classification_report"
      ],
      "metadata": {
        "id": "62AefsLpNiTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Jz3QlAbR6wBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Brand in news article\n"
      ],
      "metadata": {
        "id": "MwBY37mRbKjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)\n",
        "headline, body = article\n",
        "\n",
        "brand_by_headline = brand_identifier.predict_by_headline(headline)\n",
        "print(brand_by_headline)\n",
        "\n",
        "# Only use article body if no brand identified in the headline\n",
        "if brand_by_headline == None:\n",
        "    brand = brand_identifier.predict(body)\n",
        "    print(brand)"
      ],
      "metadata": {
        "id": "gUgFEXqubJwk",
        "outputId": "af17cf7f-f268-4d70-8af4-916526827cea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n",
            "Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify article using chosen pipeline"
      ],
      "metadata": {
        "id": "HoTrh-sEUeRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifier = SentimentIdentification(MODEL_NAME =  \"analyze_sentimentdl_glove_imdb\")\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # Uses https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "identifier_pretrained.predict_string_list([headline, body])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMwzvEYnPKEQ",
        "outputId": "4ed43c3c-0c33-4bbe-fd35-f354fce81db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n",
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'negative']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the accuracy of sentiment using the Financial News Headline Dataset"
      ],
      "metadata": {
        "id": "5GVcdPcr3Ldk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load NER Test Data"
      ],
      "metadata": {
        "id": "-QvbGQDaOR3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Kaggle data to Pandas dataframe and preprocess\n",
        "\n",
        "# Load the data from Github\n",
        "NER_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/NER_test_data.csv'\n",
        "\n",
        "df_NER = pd.read_csv(NER_url).head(500)\n",
        "df_NER.columns = ['Brand', 'Headline']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "df_NER = df_NER.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 10\n",
        "total_num_sentences = df_NER.shape[0]\n",
        "df_NER.drop(df_NER.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "print(df_NER.shape)"
      ],
      "metadata": {
        "id": "p7fSpePI1K-G",
        "outputId": "a29b69d6-0a60-4c15-f1a4-dda0d241da66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identfify the brand in each sentence & compute accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "_NYARSWW3-X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)\n",
        "\n",
        "preds = []\n",
        "for hl in df_NER['Headline']:\n",
        "    preds.append(brand_identifier.predict_by_headline(hl))\n",
        "df_NER['Predicted Brand'] = preds\n",
        "\n",
        "# Compute the accuracy\n",
        "y_true = df_NER['Brand'].to_numpy()\n",
        "y_pred = df_NER['Predicted Brand'].to_numpy()\n",
        "\n",
        "print(f\"The accuracy is {100*sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "id": "qOjUHGMw4DlA",
        "outputId": "9a22498d-68e2-48f1-ba7e-224022240011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n",
            "The accuracy is 10.0%. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Spark Dataframe as input"
      ],
      "metadata": {
        "id": "ehtVDL9_X5lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "\n",
        "# Convert to spark dataframe for faster prediction\n",
        "df_spark = spark.createDataFrame(df_NER) \n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Define pretrained pipeline\n",
        "brand_identifier = BrandIdentification(\"ner_dl_bert\")\n",
        "df_spark = brand_identifier.pipeline_model.transform(df_spark)\n",
        "\n",
        "print(df_spark.first()['class'])\n",
        "df_spark.printSchema()\n",
        "\n",
        "# Extract sentiment score\n",
        "df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                    col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                    col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "\n",
        "# df_spark_scores = df_spark_scores.withColumn('max_val', greatest('positive', 'negative', 'neutral')) # Doesn't work because of scientific notation\n",
        "\n",
        "# Extract only targets and labels\n",
        "df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "\n",
        "# # df_spark_no_text = df_spark.select(\"True_Sentiment\", \"result\")\n",
        "# # df_spark_no_text = df_spark_no_text.withColumn(\"Predicted_Sentiment\", array_join(\"result\", \"\"))\n",
        "\n",
        "# Rename to Predicted Sentiment\n",
        "df_spark = df_spark.withColumnRenamed(\"result\",\"Predicted_Sentiment\")\n",
        "\n",
        "# Convert sentiment from a list to a string\n",
        "df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "# Merge the predictions and the confidence scores\n",
        "\n",
        "# Add temporary column index to join\n",
        "w = Window.orderBy(monotonically_increasing_id())\n",
        "df_spark_with_index =  df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "df_spark_scores_with_index =  df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "# Join the predictions and the scores in one dataframe\n",
        "df_spark_with_index = df_spark_with_index.join(df_spark_scores_with_index,\n",
        "                         df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "                         'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "# Remove the index column\n",
        "df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "# Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "df_pandas_postprocessed = df_spark_combined.toPandas()\n",
        "# df_pandas_postprocessed = df_spark.toPandas()\n",
        "\n",
        "# df_pandas[\"Predicted_Sentiment\"] = df_pandas[\"Predicted_Sentiment\"].apply(lambda x: x[0]) # Alternative to convert list to string\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# df_pandas_post_processed\n"
      ],
      "metadata": {
        "id": "-ApKGkAkX5ls",
        "outputId": "37e123a9-98b6-45e6-e43b-2c14f6c984fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f56cee3124ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Measure how long it takes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Define pretrained pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the Accuracy"
      ],
      "metadata": {
        "id": "ngI8LISYX5lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Compute the accuracy\n",
        "accuracy = accuracy_score(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"])\n",
        "print(f\"The accuracy is {accuracy*100}%.\")\n",
        "print(classification_report(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"]))\n",
        "\n",
        "# Alternatively if not converted to pandas dataframe, use the following for the accuracy\n",
        "# Compute accuracy by comparing each true label with predicted label\n",
        "start = time.time()\n",
        "accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to calculate accuracy of {num_sentences} sentences.\")\n",
        "print(f\"The accuracy is {accuracy*100}%.\")"
      ],
      "metadata": {
        "id": "p6kp79NaX5lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Sentiment Test data"
      ],
      "metadata": {
        "id": "LA3mYD2kK2V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Kaggle data to Pandas dataframe and preprocess\n",
        "import time\n",
        "\n",
        "sentiment_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/sentiment_test_data.csv'\n",
        "\n",
        "# Store data in a Pandas Dataframe\n",
        "df_pandas = pd.read_csv(sentiment_url, header=None)\n",
        "\n",
        "# Change column names (pipelines require a \"text\" column to predict)\n",
        "df_pandas.columns = ['True_Sentiment', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "# df_pandas = df_pandas.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 10\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "print(df_pandas.shape)\n",
        "\n",
        "# Create a preprocessed spark dataframe\n",
        "from pyspark import SparkFiles\n",
        "spark.sparkContext.addFile(sentiment_url)\n",
        "\n",
        "# Read raw dataframe\n",
        "df_spark = spark.read.csv(\"file://\"+SparkFiles.get(\"sentiment_test_data.csv\"))\n",
        "\n",
        "# Rename columns\n",
        "df_spark = df_spark.withColumnRenamed(\"_c0\", \"True_Sentiment\").withColumnRenamed(\"_c1\", \"text\")\n",
        "df_spark = df_spark.limit(num_sentences)"
      ],
      "metadata": {
        "id": "nwLHDZohOPJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb1a6a6-c4d4-477b-c104-3a5d6660630d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Pandas Dataframe as input"
      ],
      "metadata": {
        "id": "PJc83LMsgJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "\n",
        "# Create identifier\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "start = time.time()\n",
        "df_pandas_postprocessed = identifier_pretrained.predict_dataframe(df_pandas)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "display(df_pandas_postprocessed)\n",
        "\n",
        "# Print accuracy metrics\n",
        "accuracy, report = identifier_pretrained.compute_accuracy(df_pandas_postprocessed)\n",
        "print(accuracy)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "plG0dY_MZu5Z",
        "outputId": "74cba879-f981-4532-8fed-1d2d0091d215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "3.635385513305664 seconds elapsed to classify 10 sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4709324-dac4-4b8c-85a0-9a3c365acf7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2.4731454E-4</td>\n",
              "      <td>0.9997521</td>\n",
              "      <td>5.7060873E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5.653346E-9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.508257E-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>6.0036582E-5</td>\n",
              "      <td>1.2690238E-5</td>\n",
              "      <td>0.9999273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999917</td>\n",
              "      <td>5.6210854E-7</td>\n",
              "      <td>2.8302543E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99997413</td>\n",
              "      <td>2.5440566E-5</td>\n",
              "      <td>4.739358E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99249154</td>\n",
              "      <td>0.007491626</td>\n",
              "      <td>1.6833354E-5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999535</td>\n",
              "      <td>9.266489E-7</td>\n",
              "      <td>3.748221E-6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.997993</td>\n",
              "      <td>4.443458E-5</td>\n",
              "      <td>0.0019626305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99989295</td>\n",
              "      <td>3.288251E-6</td>\n",
              "      <td>1.03682374E-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.8207674</td>\n",
              "      <td>0.024473006</td>\n",
              "      <td>0.1547596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4709324-dac4-4b8c-85a0-9a3c365acf7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4709324-dac4-4b8c-85a0-9a3c365acf7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4709324-dac4-4b8c-85a0-9a3c365acf7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text True_Sentiment  \\\n",
              "0  According to Gran , the company has no plans t...        neutral   \n",
              "1  Technopolis plans to develop in stages an area...        neutral   \n",
              "2  The international electronic industry company ...       negative   \n",
              "3  With the new production plant the company woul...       positive   \n",
              "4  According to the company 's updated strategy f...       positive   \n",
              "5  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...       positive   \n",
              "6  For the last quarter of 2010 , Componenta 's n...       positive   \n",
              "7  In the third quarter of 2010 , net sales incre...       positive   \n",
              "8  Operating profit rose to EUR 13.1 mn from EUR ...       positive   \n",
              "9  Operating profit totalled EUR 21.1 mn , up fro...       positive   \n",
              "\n",
              "  Predicted_Sentiment      positive       neutral       negative  \n",
              "0             neutral  2.4731454E-4     0.9997521   5.7060873E-7  \n",
              "1             neutral   5.653346E-9           1.0   7.508257E-10  \n",
              "2            negative  6.0036582E-5  1.2690238E-5      0.9999273  \n",
              "3            positive    0.99999917  5.6210854E-7   2.8302543E-7  \n",
              "4            positive    0.99997413  2.5440566E-5    4.739358E-7  \n",
              "5            positive    0.99249154   0.007491626   1.6833354E-5  \n",
              "6            positive    0.99999535   9.266489E-7    3.748221E-6  \n",
              "7            positive      0.997993   4.443458E-5   0.0019626305  \n",
              "8            positive    0.99989295   3.288251E-6  1.03682374E-4  \n",
              "9            positive     0.8207674   0.024473006      0.1547596  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00         1\n",
            "     neutral       1.00      1.00      1.00         2\n",
            "    positive       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict using Spark Dataframe Input"
      ],
      "metadata": {
        "id": "EDnSYA1jzkNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create identifier\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "start = time.time()\n",
        "# df_pandas_postprocessed = identifier_pretrained.predict_sp_dataframe(df_spark)\n",
        "df_pandas_postprocessed = identifier_pretrained.predict_dataframe(df_spark)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "display(df_pandas_postprocessed)"
      ],
      "metadata": {
        "id": "atfuAY97ztbD",
        "outputId": "ce197573-776e-400f-aae9-29bf24da0859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "4.103961944580078 seconds elapsed to classify 10 sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f20d3f76-38b4-402c-83b2-048678b92ec2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2.4731454E-4</td>\n",
              "      <td>0.9997521</td>\n",
              "      <td>5.7060873E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5.653346E-9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.508257E-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>6.0036582E-5</td>\n",
              "      <td>1.2690238E-5</td>\n",
              "      <td>0.9999273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999917</td>\n",
              "      <td>5.6210854E-7</td>\n",
              "      <td>2.8302543E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99997413</td>\n",
              "      <td>2.5440639E-5</td>\n",
              "      <td>4.739358E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99249154</td>\n",
              "      <td>0.007491626</td>\n",
              "      <td>1.6833354E-5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999535</td>\n",
              "      <td>9.266489E-7</td>\n",
              "      <td>3.748221E-6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.997993</td>\n",
              "      <td>4.443458E-5</td>\n",
              "      <td>0.0019626305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99989295</td>\n",
              "      <td>3.2882856E-6</td>\n",
              "      <td>1.03683466E-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.8207688</td>\n",
              "      <td>0.024472848</td>\n",
              "      <td>0.15475844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f20d3f76-38b4-402c-83b2-048678b92ec2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f20d3f76-38b4-402c-83b2-048678b92ec2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f20d3f76-38b4-402c-83b2-048678b92ec2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text True_Sentiment  \\\n",
              "0  According to Gran , the company has no plans t...        neutral   \n",
              "1  Technopolis plans to develop in stages an area...        neutral   \n",
              "2  The international electronic industry company ...       negative   \n",
              "3  With the new production plant the company woul...       positive   \n",
              "4  According to the company 's updated strategy f...       positive   \n",
              "5  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...       positive   \n",
              "6  For the last quarter of 2010 , Componenta 's n...       positive   \n",
              "7  In the third quarter of 2010 , net sales incre...       positive   \n",
              "8  Operating profit rose to EUR 13.1 mn from EUR ...       positive   \n",
              "9  Operating profit totalled EUR 21.1 mn , up fro...       positive   \n",
              "\n",
              "  Predicted_Sentiment      positive       neutral       negative  \n",
              "0             neutral  2.4731454E-4     0.9997521   5.7060873E-7  \n",
              "1             neutral   5.653346E-9           1.0   7.508257E-10  \n",
              "2            negative  6.0036582E-5  1.2690238E-5      0.9999273  \n",
              "3            positive    0.99999917  5.6210854E-7   2.8302543E-7  \n",
              "4            positive    0.99997413  2.5440639E-5    4.739358E-7  \n",
              "5            positive    0.99249154   0.007491626   1.6833354E-5  \n",
              "6            positive    0.99999535   9.266489E-7    3.748221E-6  \n",
              "7            positive      0.997993   4.443458E-5   0.0019626305  \n",
              "8            positive    0.99989295  3.2882856E-6  1.03683466E-4  \n",
              "9            positive     0.8207688   0.024472848     0.15475844  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the sentiment in each sentence one by one"
      ],
      "metadata": {
        "id": "0jQZPrKIOP3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the identifier object\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # 90.2% accuracy on 500 sentences 89.8% on 1000 sentences\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "\n",
        "\n",
        "\n",
        "preds = []\n",
        "target = []\n",
        "ignored_idxs = []\n",
        "sentiment_to_ignore = \"\" # e.g. neutral\n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Collect predicted sentiment for each headline - take three minutes to run\n",
        "for idx, hl in enumerate(df_pandas['text']):\n",
        "\n",
        "    # Only append the sentiment if it is not the sentiment to ignore (e.g. neutral)\n",
        "    target_sentiment = df_pandas[\"True_Sentiment\"][df_pandas.index[idx]]\n",
        "\n",
        "    if target_sentiment != sentiment_to_ignore:\n",
        "      preds.append(identifier.predict_string_list([hl]))\n",
        "    else:\n",
        "      ignored_idxs.append(idx)\n",
        "\n",
        "    # Print progress\n",
        "    if idx % 25 == 0:\n",
        "      print(f\"Classification {100*idx/num_sentences}% done.\")\n",
        "\n",
        "# Remove all ignored entries from dataset\n",
        "df_pandas.drop(df_pandas.index[ignored_idxs], inplace=True)\n",
        "\n",
        "df_pandas['Predicted_Sentiment'] = preds\n",
        "\n",
        "# Measure how long it takes\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Modify predicted labels to match with true labels\n",
        "# df = df.replace({'Predicted Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "df_pandas"
      ],
      "metadata": {
        "id": "5jFhoWw54zMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure the Accuracy"
      ],
      "metadata": {
        "id": "OugF9Z-6t0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = df_pandas['True_Sentiment'].to_numpy()\n",
        "y_pred = df_pandas['Predicted_Sentiment'].to_numpy()\n",
        "\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "\n",
        "# Compute classification metrics - poor accuracy\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "JiLV0Glo_Kzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Copy of CLASS FOR SENTIMENT DETECTION USING SNOW LABS PIPELINES.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}