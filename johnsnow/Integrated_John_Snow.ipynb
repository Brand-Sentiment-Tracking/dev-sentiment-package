{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/python-package/blob/main/johnsnow/Integrated_John_Snow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYgZXG4gDt1"
      },
      "source": [
        "# **Class for Sentiment Analysis for News Articles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDySD2IHU9di",
        "outputId": "62a240ae-acdd-466e-c364-b6eb88982403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 55 kB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 61.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 70.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOW8Mt7VH97",
        "outputId": "1282ed5b-6cf6-4db2-ff36-877657fe0ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.1\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "# spark = sparknlp.start(gpu=False)\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a News Article"
      ],
      "metadata": {
        "id": "BDijGosdPGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = [ # two strings - headline & article body\n",
        "\"\"\"Google sued in US over 'deceptive' location tracking\"\"\", # headline\n",
        "\"\"\"Google is being sued in the US over accusations it deceived people about how to control location tracking.\n",
        "\n",
        "The legal action refers to a widely reported 2018 revelation turning off one location-tracking setting in its apps was insufficient to fully disable the feature.\n",
        "\n",
        "It accuses Google of using so-called dark patterns, marketing techniques that deliberately confuse.\n",
        "\n",
        "Google said the claims were inaccurate and outdated.\n",
        "\n",
        "'Unfair practices'\n",
        "The legal action was filed in the District of Columbia. Similar ones were also filed in Texas, Indiana and Washington state.\n",
        "\n",
        "It refers to an Associated Press revelation turning off Location History when using Google Maps or Search was insufficient - as a separate setting, Web and App Activity, continued to log location and other personal data.\n",
        "\n",
        "The study, with researchers at Princeton University, found up to two billion Android and Apple devices could be affected.\n",
        "\n",
        "\"Google has relied on, and continues to rely on, deceptive and unfair practices that make it difficult for users to decline location tracking or to evaluate the data collection and processing to which they are purportedly consenting,\" the legal action alleges.\n",
        "\n",
        "'Robust controls'\n",
        "Google told BBC News the case was based \"on inaccurate claims and outdated assertions about our settings\".\n",
        "\n",
        "A representative added: \"We have always built privacy features into our products and provided robust controls for location data.\n",
        "\n",
        "\"We will vigorously defend ourselves and set the record straight.\"\n",
        "\n",
        "Visual misdirection\n",
        "The legal action claims Google's policies contained other \"misleading, ambiguous and incomplete descriptions... but guarantee that consumers will not understand when their location is collected and retained by Google or for what purposes\".\n",
        "\n",
        "It refers to dark patterns, design choices that alter users' decision-making for the designer's benefit - such as, complicated navigation menus, visual misdirection, confusing wording and repeated nudging towards a particular outcome.\n",
        "\n",
        "Data regulators are increasingly focusing on these practices.\n",
        "\n",
        "Google faces a raft of other legal actions in the US, including:\n",
        "\n",
        "In May 2020, Arizona filed a legal action over the same issue\n",
        "In December 2020, multiple US states sued over the price and process of advertising auctions\n",
        "In October 2020, the US Justice Department alleged Google had a monopoly over search and search advertising\"\"\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "kzD5yHCBTfKL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Brand Identification Class"
      ],
      "metadata": {
        "id": "rmq_-RXkbB1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_brand(row_list):\n",
        "    if not row_list: # If the list is empty\n",
        "        return \"None\"\n",
        "\n",
        "    else:\n",
        "        # Create a pandas df with entity names and types\n",
        "        data = [[row.result, row.metadata['entity']] for row in row_list]\n",
        "        df_pd = pd.DataFrame(data, columns = ['Entity', 'Type'])\n",
        "      \n",
        "        # Filter only ORGs\n",
        "        df_pd = df_pd[df_pd[\"Type\"] == \"ORG\"]\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df_pd[\"Entity\"].value_counts() # a Pandas Series object\n",
        "            \n",
        "        # If no ORG identified in headline, return None\n",
        "        if len(ranked_df.index) == 0:\n",
        "           return \"None\"\n",
        "\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif len(ranked_df.index) == 1:\n",
        "           return ranked_df.index[0]\n",
        "\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df[0] > ranked_df[1]:\n",
        "            return ranked_df.index[0] \n",
        "\n",
        "        else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "            return random.choice([ranked_df.index[0], ranked_df.index[1]])\n",
        "            # TO DO: break even - Wikidata for article body #"
      ],
      "metadata": {
        "id": "OdQPrJe86RQz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text') # An empty df with column name \"text\"\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def predict_brand(self, text): # text could be a pandas dataframe or a Spark dataframe (with a column \"text\"), a list of strings\n",
        "        # Run the pipeline for the text\n",
        "        if isinstance(text, pd.DataFrame): \n",
        "            text_df = spark.createDataFrame(text) # If input a pandas dataframe\n",
        "        elif isinstance(text, list): \n",
        "            text_df = spark.createDataFrame(pd.DataFrame({'text': text})) # If input a list of strings\n",
        "        elif isinstance(text, str): \n",
        "            text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index=[0])) # If input a single string\n",
        "        else: text_df = text\n",
        "\n",
        "        df_spark = self.pipeline_model.transform(text_df) \n",
        "\n",
        "        # Improve speed of identification using Spark User-defined function\n",
        "        pred_brand = F.udf(lambda z: get_brand(z), StringType()) # Output a string\n",
        "        # spark.udf.register(\"pred_brand\", pred_brand)\n",
        "\n",
        "        df_spark_combined = df_spark.withColumn('Predicted_brand', pred_brand('ner_chunk'))\n",
        "        df_spark_combined = df_spark_combined.select(\"text\", \"Predicted_brand\")\n",
        "        # df_spark_combined.show(100)\n",
        "        \n",
        "        # Remove all rows with no brands detected\n",
        "        df_spark_final=df_spark_combined.filter(df_spark_combined.Predicted_brand != 'None')\n",
        "        df_spark_final.show(100)\n",
        "\n",
        "        return df_spark_final\n"
      ],
      "metadata": {
        "id": "sYVn0VZzc-Yf"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Senitment Identification Class"
      ],
      "metadata": {
        "id": "-5m65UosNdY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "          # Create a custom pipline if requested\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "            document_assembler = DocumentAssembler() \\\n",
        "                .setInputCol('text') \\\n",
        "                .setOutputCol('document')\n",
        "\n",
        "            tokenizer = Tokenizer() \\\n",
        "                .setInputCols(['document']) \\\n",
        "                .setOutputCol('token')\n",
        "\n",
        "            sequenceClassifier = BertForSequenceClassification \\\n",
        "                  .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                  .setInputCols(['token', 'document']) \\\n",
        "                  .setOutputCol('class') \\\n",
        "                  .setCaseSensitive(True) \\\n",
        "                  .setMaxSentenceLength(512)\n",
        "\n",
        "            pipeline = Pipeline(stages=[\n",
        "                document_assembler,\n",
        "                tokenizer,\n",
        "                sequenceClassifier\n",
        "            ])\n",
        "\n",
        "            self.pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))\n",
        "\n",
        "        else:\n",
        "            self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "    def predict_string_list(self, string_list):\n",
        "        \"\"\"Predicts sentiment of the input list of strings.\n",
        "\n",
        "        Args:\n",
        "          string_list: List of strings to classify.\n",
        "        \"\"\"\n",
        " \n",
        "        # Annotate input text using pretrained model\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "            pipeline_annotator = LightPipeline(self.pipeline_model) # Convert the pipeline to an annotator\n",
        "        else:\n",
        "            pipeline_annotator = self.pipeline_model\n",
        "\n",
        "        annotations =  pipeline_annotator.annotate(string_list)\n",
        "\n",
        "        return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "\n",
        "\n",
        "    def predict_dataframe(self, df):\n",
        "        \"\"\"Annotates the input dataframe with the classification results.\n",
        "\n",
        "        Args:\n",
        "          df : Pandas or Spark dataframe to classify (must contain a \"text\" column)\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(df, pd.DataFrame):\n",
        "            # Convert to spark dataframe for faster prediction\n",
        "            df_spark = spark.createDataFrame(df) \n",
        "        else:\n",
        "            df_spark = df\n",
        "\n",
        "        # Annotate dataframe with classification results\n",
        "        df_spark = self.pipeline_model.transform(df_spark)\n",
        "\n",
        "        #Extract sentiment score\n",
        "        df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                            col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                            col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "\n",
        "        # Extract only target and label columns\n",
        "        df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "        # Rename to result column to Predicted Sentiment\n",
        "        df_spark = df_spark.withColumnRenamed(\"result\", \"Predicted_Sentiment\")\n",
        "\n",
        "        # Convert sentiment from a list to a string\n",
        "        df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "        # Join the predictions dataframe to the scores dataframe\n",
        "        # Add temporary column index to join\n",
        "        w = Window.orderBy(monotonically_increasing_id())\n",
        "        df_spark_with_index =  df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "        df_spark_scores_with_index =  df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "        # Join the predictions and the scores in one dataframe\n",
        "        df_spark_with_index = df_spark_with_index.join(df_spark_scores_with_index,\n",
        "                                df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "                                'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "        # Remove the index column\n",
        "        df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "        # Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "        df_pandas_postprocessed = df_spark_combined.toPandas()\n",
        "\n",
        "        return df_pandas_postprocessed\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, df_pandas_postprocessed):\n",
        "        \"\"\"Computes accuracy by comparing labels of input dataframe.\n",
        "\n",
        "        Args:\n",
        "          df_pandas_postprocessed: pandas dataframe containing \"True_Sentiment\" and \"Predicted_Sentiment\" columns\n",
        "        \"\"\"\n",
        "    \n",
        "        from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "        # Compute the accuracy\n",
        "        accuracy = accuracy_score(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "        accuracy *= 100\n",
        "        classification_report = classification_report(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "\n",
        "        # Alternatively if the input is a postprocessed spark dataframe\n",
        "        # Compute accuracy by comparing each true label with predicted label\n",
        "        # accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "\n",
        "        return accuracy, classification_report"
      ],
      "metadata": {
        "id": "62AefsLpNiTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Jz3QlAbR6wBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Brand in news article\n"
      ],
      "metadata": {
        "id": "MwBY37mRbKjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjgGRSs4MiG",
        "outputId": "da36d1f1-54c0-4cb7-c161-83e00d884084"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline, body = article\n",
        "\n",
        "brand_by_headline = brand_identifier.predict_brand(headline)\n",
        "\n",
        "# Only use article body if no brand identified in the headline\n",
        "if brand_by_headline.count() == 0:\n",
        "    brand_by_body = brand_identifier.predict_brand(body)"
      ],
      "metadata": {
        "id": "gUgFEXqubJwk",
        "outputId": "c84e38b1-10b9-4d06-8caf-04557bdc3ced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+\n",
            "|              text|Predicted_brand|\n",
            "+------------------+---------------+\n",
            "|Bad news for Tesla|           None|\n",
            "+------------------+---------------+\n",
            "\n",
            "+----+---------------+\n",
            "|text|Predicted_brand|\n",
            "+----+---------------+\n",
            "+----+---------------+\n",
            "\n",
            "+--------------------+---------------+\n",
            "|                text|Predicted_brand|\n",
            "+--------------------+---------------+\n",
            "|Tesla went bankru...|          Tesla|\n",
            "+--------------------+---------------+\n",
            "\n",
            "+--------------------+---------------+\n",
            "|                text|Predicted_brand|\n",
            "+--------------------+---------------+\n",
            "|Tesla went bankru...|          Tesla|\n",
            "+--------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_hl = [\"Bad news for Google\", \"Tesla went bankrupt today.\"]\n",
        "brands = brand_identifier.predict_brand(list_of_hl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2fIFzbU_j_K",
        "outputId": "540e2f61-84a8-426b-c0e0-11f31643554e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|                text|Predicted Brand|\n",
            "+--------------------+---------------+\n",
            "| Bad news for Google|         Google|\n",
            "|Tesla went bankru...|          Tesla|\n",
            "+--------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify article using chosen pipeline"
      ],
      "metadata": {
        "id": "HoTrh-sEUeRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifier = SentimentIdentification(MODEL_NAME =  \"analyze_sentimentdl_glove_imdb\")\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # Uses https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "identifier_pretrained.predict_string_list([headline, body])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMwzvEYnPKEQ",
        "outputId": "4ed43c3c-0c33-4bbe-fd35-f354fce81db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n",
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'negative']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the accuracy of sentiment using the Financial News Headline Dataset"
      ],
      "metadata": {
        "id": "5GVcdPcr3Ldk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER "
      ],
      "metadata": {
        "id": "-QvbGQDaOR3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Kaggle data to Pandas dataframe and preprocess"
      ],
      "metadata": {
        "id": "QpKHFStDuQJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from Github\n",
        "NER_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/NER_test_data.csv'\n",
        "\n",
        "# Convert csv data to Pandas dataframe \n",
        "df_NER = pd.read_csv(NER_url, header=None).head(500) # 'header=None' prevents pandas eating the first row as headers\n",
        "df_NER.columns = ['Brand', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "# df_NER = df_NER.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 10\n",
        "total_num_sentences = df_NER.shape[0]\n",
        "df_NER.drop(df_NER.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Alternatively, create a preprocessed spark dataframe from csv\n",
        "from pyspark import SparkFiles\n",
        "spark.sparkContext.addFile(NER_url)\n",
        "\n",
        "# Read raw dataframe\n",
        "df_spark_org = spark.read.csv(\"file://\"+SparkFiles.get(\"NER_test_data.csv\"))\n",
        "\n",
        "# Rename columns\n",
        "df_spark_org = df_spark_org.withColumnRenamed(\"_c0\", \"Brand\").withColumnRenamed(\"_c1\", \"text\")\n",
        "df_spark_org = df_spark_org.limit(num_sentences)"
      ],
      "metadata": {
        "id": "p7fSpePI1K-G"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the brand in each sentence & compute accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "_NYARSWW3-X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\" / \"ner_dl\"\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGW3Pdx9_4q7",
        "outputId": "a4851d8d-730a-45e8-dd11-6594e2e39d47"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify all brands using Spark Dataframe of sentences as input "
      ],
      "metadata": {
        "id": "ehtVDL9_X5lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brand_identifier.predict_brand(df_NER)\n",
        "brand_identifier.predict_brand(df_spark_org)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKDd3hNN7-Dj",
        "outputId": "12539095-2744-4784-aa93-2b116a9a8c25"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|                text|Predicted Brand|\n",
            "+--------------------+---------------+\n",
            "|According to Gran...|           Gran|\n",
            "|Technopolis plans...|    Technopolis|\n",
            "|The international...|      Postimees|\n",
            "|With the new prod...|           None|\n",
            "|According to the ...|        Basware|\n",
            "|FINANCING OF ASPO...|       ASPOCOMP|\n",
            "|For the last quar...|     Componenta|\n",
            "|In the third quar...|            EUR|\n",
            "|Operating profit ...|           None|\n",
            "|Operating profit ...|           None|\n",
            "+--------------------+---------------+\n",
            "\n",
            "+--------------------+---------------+\n",
            "|                text|Predicted Brand|\n",
            "+--------------------+---------------+\n",
            "|According to Gran...|           Gran|\n",
            "|Technopolis plans...|    Technopolis|\n",
            "|The international...|        Elcoteq|\n",
            "|With the new prod...|           None|\n",
            "|According to the ...|        Basware|\n",
            "|FINANCING OF ASPO...|       ASPOCOMP|\n",
            "|For the last quar...|     Componenta|\n",
            "|In the third quar...|            EUR|\n",
            "|Operating profit ...|           None|\n",
            "|Operating profit ...|           None|\n",
            "+--------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve speed of identification using Spark User-defined function\n",
        "dataframe_type = \"Spark\"\n",
        "\n",
        "if dataframe_type == \"Pandas\": df_spark_org = spark.createDataFrame(df_NER)  # Only keep the 'text' column\n",
        "df_spark = brand_identifier.pipeline_model.transform(df_spark_org)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pred_brand = F.udf(lambda z: get_brand(z), StringType()) # Output a string\n",
        "# spark.udf.register(\"pred_brand\", pred_brand)\n",
        "\n",
        "def get_brand(row_list):\n",
        "    if not row_list: # If the list is empty\n",
        "        return \"None\"\n",
        "\n",
        "    else:\n",
        "        # Create a pandas df with entity names and types\n",
        "        data = [[row.result, row.metadata['entity']] for row in row_list]\n",
        "        df_pd = pd.DataFrame(data, columns = ['Entity', 'Type'])\n",
        "  \n",
        "        # Filter only ORGs\n",
        "        df_pd = df_pd[df_pd[\"Type\"] == \"ORG\"]\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df_pd[\"Entity\"].value_counts() # a Pandas Series object\n",
        "        \n",
        "        # If no ORG identified in headline, return None\n",
        "        if len(ranked_df.index) == 0:\n",
        "           return \"None\"\n",
        "\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif len(ranked_df.index) == 1:\n",
        "           return ranked_df.index[0]\n",
        "\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df[0] > ranked_df[1]:\n",
        "            return ranked_df.index[0] \n",
        "\n",
        "        else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "            return random.choice([ranked_df.index[0], ranked_df.index[1]])\n",
        "\n",
        "# pred_brand_col = pred_brand(df_spark.ner_chunk)\n",
        "df_spark_combined = df_spark.withColumn('Predicted Brand', pred_brand('ner_chunk'))\n",
        "df_spark_final = df_spark_combined.select(\"Brand\", \"Predicted Brand\")\n",
        "df_spark_final.show(100)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to create ranked tables for {num_sentences} sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9smD7qJWX5X",
        "outputId": "370e6ac6-b8fc-4463-94ff-f8a31e0dcfff"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+\n",
            "|       Brand|Predicted Brand|\n",
            "+------------+---------------+\n",
            "|        None|           Gran|\n",
            "|Technopolis |    Technopolis|\n",
            "|     Elcoteq|        Elcoteq|\n",
            "|        None|           None|\n",
            "|     Basware|        Basware|\n",
            "|    Aspocomp|       ASPOCOMP|\n",
            "|  Componenta|     Componenta|\n",
            "|        None|            EUR|\n",
            "|        None|           None|\n",
            "|        None|           None|\n",
            "+------------+---------------+\n",
            "\n",
            "0.7330765724182129 seconds elapsed to create ranked tables for 10 sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the accuracy\n",
        "df_pd_post = df_spark_final.toPandas()\n",
        "\n",
        "y_true = df_pd_post['Brand'].to_numpy()\n",
        "y_pred = df_pd_post['Predicted Brand'].to_numpy()\n",
        "print(f\"The accuracy is {100*sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBnLS_2bzRZ4",
        "outputId": "a1ac3323-12a8-49aa-8298-259219c23b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 61.0%. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment"
      ],
      "metadata": {
        "id": "zqhY6YdzDOxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Sentiment Test data"
      ],
      "metadata": {
        "id": "LA3mYD2kK2V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Kaggle data to Pandas dataframe and preprocess\n",
        "import time\n",
        "\n",
        "sentiment_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/sentiment_test_data.csv'\n",
        "\n",
        "# Store data in a Pandas Dataframe\n",
        "df_pandas = pd.read_csv(sentiment_url, header=None)\n",
        "\n",
        "# Change column names (pipelines require a \"text\" column to predict)\n",
        "df_pandas.columns = ['True_Sentiment', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "# df_pandas = df_pandas.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 10\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "print(df_pandas.shape)\n",
        "\n",
        "# Create a preprocessed spark dataframe\n",
        "from pyspark import SparkFiles\n",
        "spark.sparkContext.addFile(sentiment_url)\n",
        "\n",
        "# Read raw dataframe\n",
        "df_spark = spark.read.csv(\"file://\"+SparkFiles.get(\"sentiment_test_data.csv\"))\n",
        "\n",
        "# Rename columns\n",
        "df_spark = df_spark.withColumnRenamed(\"_c0\", \"True_Sentiment\").withColumnRenamed(\"_c1\", \"text\")\n",
        "df_spark = df_spark.limit(num_sentences)"
      ],
      "metadata": {
        "id": "nwLHDZohOPJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb1a6a6-c4d4-477b-c104-3a5d6660630d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Pandas Dataframe as input"
      ],
      "metadata": {
        "id": "PJc83LMsgJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "\n",
        "# Create identifier\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "start = time.time()\n",
        "df_pandas_postprocessed = identifier_pretrained.predict_dataframe(df_pandas)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "display(df_pandas_postprocessed)\n",
        "\n",
        "# Print accuracy metrics\n",
        "accuracy, report = identifier_pretrained.compute_accuracy(df_pandas_postprocessed)\n",
        "print(accuracy)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "plG0dY_MZu5Z",
        "outputId": "74cba879-f981-4532-8fed-1d2d0091d215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "3.635385513305664 seconds elapsed to classify 10 sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4709324-dac4-4b8c-85a0-9a3c365acf7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2.4731454E-4</td>\n",
              "      <td>0.9997521</td>\n",
              "      <td>5.7060873E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5.653346E-9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.508257E-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>6.0036582E-5</td>\n",
              "      <td>1.2690238E-5</td>\n",
              "      <td>0.9999273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999917</td>\n",
              "      <td>5.6210854E-7</td>\n",
              "      <td>2.8302543E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99997413</td>\n",
              "      <td>2.5440566E-5</td>\n",
              "      <td>4.739358E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99249154</td>\n",
              "      <td>0.007491626</td>\n",
              "      <td>1.6833354E-5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999535</td>\n",
              "      <td>9.266489E-7</td>\n",
              "      <td>3.748221E-6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.997993</td>\n",
              "      <td>4.443458E-5</td>\n",
              "      <td>0.0019626305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99989295</td>\n",
              "      <td>3.288251E-6</td>\n",
              "      <td>1.03682374E-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.8207674</td>\n",
              "      <td>0.024473006</td>\n",
              "      <td>0.1547596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4709324-dac4-4b8c-85a0-9a3c365acf7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4709324-dac4-4b8c-85a0-9a3c365acf7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4709324-dac4-4b8c-85a0-9a3c365acf7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text True_Sentiment  \\\n",
              "0  According to Gran , the company has no plans t...        neutral   \n",
              "1  Technopolis plans to develop in stages an area...        neutral   \n",
              "2  The international electronic industry company ...       negative   \n",
              "3  With the new production plant the company woul...       positive   \n",
              "4  According to the company 's updated strategy f...       positive   \n",
              "5  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...       positive   \n",
              "6  For the last quarter of 2010 , Componenta 's n...       positive   \n",
              "7  In the third quarter of 2010 , net sales incre...       positive   \n",
              "8  Operating profit rose to EUR 13.1 mn from EUR ...       positive   \n",
              "9  Operating profit totalled EUR 21.1 mn , up fro...       positive   \n",
              "\n",
              "  Predicted_Sentiment      positive       neutral       negative  \n",
              "0             neutral  2.4731454E-4     0.9997521   5.7060873E-7  \n",
              "1             neutral   5.653346E-9           1.0   7.508257E-10  \n",
              "2            negative  6.0036582E-5  1.2690238E-5      0.9999273  \n",
              "3            positive    0.99999917  5.6210854E-7   2.8302543E-7  \n",
              "4            positive    0.99997413  2.5440566E-5    4.739358E-7  \n",
              "5            positive    0.99249154   0.007491626   1.6833354E-5  \n",
              "6            positive    0.99999535   9.266489E-7    3.748221E-6  \n",
              "7            positive      0.997993   4.443458E-5   0.0019626305  \n",
              "8            positive    0.99989295   3.288251E-6  1.03682374E-4  \n",
              "9            positive     0.8207674   0.024473006      0.1547596  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00         1\n",
            "     neutral       1.00      1.00      1.00         2\n",
            "    positive       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict using Spark Dataframe Input"
      ],
      "metadata": {
        "id": "EDnSYA1jzkNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create identifier\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "start = time.time()\n",
        "# df_pandas_postprocessed = identifier_pretrained.predict_sp_dataframe(df_spark)\n",
        "df_pandas_postprocessed = identifier_pretrained.predict_dataframe(df_spark)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "display(df_pandas_postprocessed)"
      ],
      "metadata": {
        "id": "atfuAY97ztbD",
        "outputId": "ce197573-776e-400f-aae9-29bf24da0859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "4.103961944580078 seconds elapsed to classify 10 sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f20d3f76-38b4-402c-83b2-048678b92ec2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2.4731454E-4</td>\n",
              "      <td>0.9997521</td>\n",
              "      <td>5.7060873E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5.653346E-9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.508257E-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>6.0036582E-5</td>\n",
              "      <td>1.2690238E-5</td>\n",
              "      <td>0.9999273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999917</td>\n",
              "      <td>5.6210854E-7</td>\n",
              "      <td>2.8302543E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99997413</td>\n",
              "      <td>2.5440639E-5</td>\n",
              "      <td>4.739358E-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99249154</td>\n",
              "      <td>0.007491626</td>\n",
              "      <td>1.6833354E-5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99999535</td>\n",
              "      <td>9.266489E-7</td>\n",
              "      <td>3.748221E-6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.997993</td>\n",
              "      <td>4.443458E-5</td>\n",
              "      <td>0.0019626305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.99989295</td>\n",
              "      <td>3.2882856E-6</td>\n",
              "      <td>1.03683466E-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.8207688</td>\n",
              "      <td>0.024472848</td>\n",
              "      <td>0.15475844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f20d3f76-38b4-402c-83b2-048678b92ec2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f20d3f76-38b4-402c-83b2-048678b92ec2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f20d3f76-38b4-402c-83b2-048678b92ec2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text True_Sentiment  \\\n",
              "0  According to Gran , the company has no plans t...        neutral   \n",
              "1  Technopolis plans to develop in stages an area...        neutral   \n",
              "2  The international electronic industry company ...       negative   \n",
              "3  With the new production plant the company woul...       positive   \n",
              "4  According to the company 's updated strategy f...       positive   \n",
              "5  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...       positive   \n",
              "6  For the last quarter of 2010 , Componenta 's n...       positive   \n",
              "7  In the third quarter of 2010 , net sales incre...       positive   \n",
              "8  Operating profit rose to EUR 13.1 mn from EUR ...       positive   \n",
              "9  Operating profit totalled EUR 21.1 mn , up fro...       positive   \n",
              "\n",
              "  Predicted_Sentiment      positive       neutral       negative  \n",
              "0             neutral  2.4731454E-4     0.9997521   5.7060873E-7  \n",
              "1             neutral   5.653346E-9           1.0   7.508257E-10  \n",
              "2            negative  6.0036582E-5  1.2690238E-5      0.9999273  \n",
              "3            positive    0.99999917  5.6210854E-7   2.8302543E-7  \n",
              "4            positive    0.99997413  2.5440639E-5    4.739358E-7  \n",
              "5            positive    0.99249154   0.007491626   1.6833354E-5  \n",
              "6            positive    0.99999535   9.266489E-7    3.748221E-6  \n",
              "7            positive      0.997993   4.443458E-5   0.0019626305  \n",
              "8            positive    0.99989295  3.2882856E-6  1.03683466E-4  \n",
              "9            positive     0.8207688   0.024472848     0.15475844  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the sentiment in each sentence one by one"
      ],
      "metadata": {
        "id": "0jQZPrKIOP3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the identifier object\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # 90.2% accuracy on 500 sentences 89.8% on 1000 sentences\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "\n",
        "\n",
        "\n",
        "preds = []\n",
        "target = []\n",
        "ignored_idxs = []\n",
        "sentiment_to_ignore = \"\" # e.g. neutral\n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Collect predicted sentiment for each headline - take three minutes to run\n",
        "for idx, hl in enumerate(df_pandas['text']):\n",
        "\n",
        "    # Only append the sentiment if it is not the sentiment to ignore (e.g. neutral)\n",
        "    target_sentiment = df_pandas[\"True_Sentiment\"][df_pandas.index[idx]]\n",
        "\n",
        "    if target_sentiment != sentiment_to_ignore:\n",
        "      preds.append(identifier.predict_string_list([hl]))\n",
        "    else:\n",
        "      ignored_idxs.append(idx)\n",
        "\n",
        "    # Print progress\n",
        "    if idx % 25 == 0:\n",
        "      print(f\"Classification {100*idx/num_sentences}% done.\")\n",
        "\n",
        "# Remove all ignored entries from dataset\n",
        "df_pandas.drop(df_pandas.index[ignored_idxs], inplace=True)\n",
        "\n",
        "df_pandas['Predicted_Sentiment'] = preds\n",
        "\n",
        "# Measure how long it takes\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Modify predicted labels to match with true labels\n",
        "# df = df.replace({'Predicted Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "df_pandas"
      ],
      "metadata": {
        "id": "5jFhoWw54zMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure the Accuracy"
      ],
      "metadata": {
        "id": "OugF9Z-6t0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = df_pandas['True_Sentiment'].to_numpy()\n",
        "y_pred = df_pandas['Predicted_Sentiment'].to_numpy()\n",
        "\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "\n",
        "# Compute classification metrics - poor accuracy\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "JiLV0Glo_Kzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BDijGosdPGzW",
        "-5m65UosNdY5",
        "HoTrh-sEUeRf"
      ],
      "name": "John Snow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}