{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/dev-sentiment-package/blob/main/johnsnow/Integrated_John_Snow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYgZXG4gDt1"
      },
      "source": [
        "# **Class for Sentiment Analysis for News Articles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDySD2IHU9di",
        "outputId": "7013de02-9985-4e38-9c6f-7d98ea75163c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 55 kB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 40.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOW8Mt7VH97",
        "outputId": "13a52ec9-4185-414e-e6f1-fe5b6871a2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.2\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "# spark = sparknlp.start(gpu=False)\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a News Article"
      ],
      "metadata": {
        "id": "BDijGosdPGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = [ # two strings - headline & article body\n",
        "\"\"\"Google sued in US over 'deceptive' location tracking\"\"\", # headline\n",
        "\"\"\"Google is being sued in the US over accusations it deceived people about how to control location tracking.\n",
        "\n",
        "The legal action refers to a widely reported 2018 revelation turning off one location-tracking setting in its apps was insufficient to fully disable the feature.\n",
        "\n",
        "It accuses Google of using so-called dark patterns, marketing techniques that deliberately confuse.\n",
        "\n",
        "Google said the claims were inaccurate and outdated.\n",
        "\n",
        "'Unfair practices'\n",
        "The legal action was filed in the District of Columbia. Similar ones were also filed in Texas, Indiana and Washington state.\n",
        "\n",
        "It refers to an Associated Press revelation turning off Location History when using Google Maps or Search was insufficient - as a separate setting, Web and App Activity, continued to log location and other personal data.\n",
        "\n",
        "The study, with researchers at Princeton University, found up to two billion Android and Apple devices could be affected.\n",
        "\n",
        "\"Google has relied on, and continues to rely on, deceptive and unfair practices that make it difficult for users to decline location tracking or to evaluate the data collection and processing to which they are purportedly consenting,\" the legal action alleges.\n",
        "\n",
        "'Robust controls'\n",
        "Google told BBC News the case was based \"on inaccurate claims and outdated assertions about our settings\".\n",
        "\n",
        "A representative added: \"We have always built privacy features into our products and provided robust controls for location data.\n",
        "\n",
        "\"We will vigorously defend ourselves and set the record straight.\"\n",
        "\n",
        "Visual misdirection\n",
        "The legal action claims Google's policies contained other \"misleading, ambiguous and incomplete descriptions... but guarantee that consumers will not understand when their location is collected and retained by Google or for what purposes\".\n",
        "\n",
        "It refers to dark patterns, design choices that alter users' decision-making for the designer's benefit - such as, complicated navigation menus, visual misdirection, confusing wording and repeated nudging towards a particular outcome.\n",
        "\n",
        "Data regulators are increasingly focusing on these practices.\n",
        "\n",
        "Google faces a raft of other legal actions in the US, including:\n",
        "\n",
        "In May 2020, Arizona filed a legal action over the same issue\n",
        "In December 2020, multiple US states sued over the price and process of advertising auctions\n",
        "In October 2020, the US Justice Department alleged Google had a monopoly over search and search advertising\"\"\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "kzD5yHCBTfKL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Brand Identification Class"
      ],
      "metadata": {
        "id": "rmq_-RXkbB1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_brand(row_list):\n",
        "    if not row_list: # If the list is empty\n",
        "        return \"None\"\n",
        "\n",
        "    else:\n",
        "        # Create a pandas df with entity names and types\n",
        "        data = [[row.result, row.metadata['entity']] for row in row_list]\n",
        "        df_pd = pd.DataFrame(data, columns = ['Entity', 'Type'])\n",
        "      \n",
        "        # Filter only ORGs\n",
        "        df_pd = df_pd[df_pd[\"Type\"] == \"ORG\"]\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df_pd[\"Entity\"].value_counts() # a Pandas Series object\n",
        "            \n",
        "        # If no ORG identified in headline, return None\n",
        "        if len(ranked_df.index) == 0:\n",
        "           return \"None\"\n",
        "\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif len(ranked_df.index) == 1:\n",
        "           return ranked_df.index[0]\n",
        "\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df[0] > ranked_df[1]:\n",
        "            return ranked_df.index[0] \n",
        "\n",
        "        else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "            return random.choice([ranked_df.index[0], ranked_df.index[1]])\n",
        "            # TO DO: break even - Wikidata for article body #"
      ],
      "metadata": {
        "id": "OdQPrJe86RQz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text') # An empty df with column name \"text\"\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def predict_brand(self, text): # text could be a pandas dataframe or a Spark dataframe (with a column \"text\"), a list of strings\n",
        "        # Run the pipeline for the text\n",
        "        if isinstance(text, pd.DataFrame): \n",
        "            text_df = spark.createDataFrame(text) # If input a pandas dataframe\n",
        "        elif isinstance(text, list): \n",
        "            text_df = spark.createDataFrame(pd.DataFrame({'text': text})) # If input a list of strings\n",
        "        elif isinstance(text, str): \n",
        "            text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index=[0])) # If input a single string\n",
        "        else: text_df = text\n",
        "\n",
        "        df_spark = self.pipeline_model.transform(text_df) \n",
        "\n",
        "        # Improve speed of identification using Spark User-defined function\n",
        "        pred_brand = F.udf(lambda z: get_brand(z), StringType()) # Output a string\n",
        "        # spark.udf.register(\"pred_brand\", pred_brand)\n",
        "\n",
        "        df_spark_combined = df_spark.withColumn('Predicted_brand', pred_brand('ner_chunk'))\n",
        "        df_spark_combined = df_spark_combined.select(\"text\", \"Predicted_brand\")\n",
        "        # df_spark_combined.show(100)\n",
        "        \n",
        "        # Remove all rows with no brands detected\n",
        "        df_spark_final=df_spark_combined.filter(df_spark_combined.Predicted_brand != 'None')\n",
        "        df_spark_final.show(100)\n",
        "\n",
        "        return df_spark_final\n"
      ],
      "metadata": {
        "id": "sYVn0VZzc-Yf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Senitment Identification Class"
      ],
      "metadata": {
        "id": "-5m65UosNdY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "          # Create a custom pipline if requested\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "            document_assembler = DocumentAssembler() \\\n",
        "                .setInputCol('text') \\\n",
        "                .setOutputCol('document')\n",
        "\n",
        "            tokenizer = Tokenizer() \\\n",
        "                .setInputCols(['document']) \\\n",
        "                .setOutputCol('token')\n",
        "\n",
        "            sequenceClassifier = BertForSequenceClassification \\\n",
        "                  .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                  .setInputCols(['token', 'document']) \\\n",
        "                  .setOutputCol('class') \\\n",
        "                  .setCaseSensitive(True) \\\n",
        "                  .setMaxSentenceLength(512)\n",
        "\n",
        "            pipeline = Pipeline(stages=[\n",
        "                document_assembler,\n",
        "                tokenizer,\n",
        "                sequenceClassifier\n",
        "            ])\n",
        "\n",
        "            self.pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))\n",
        "\n",
        "        else:\n",
        "            self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "    def predict_string_list(self, string_list):\n",
        "        \"\"\"Predicts sentiment of the input list of strings.\n",
        "\n",
        "        Args:\n",
        "          string_list: List of strings to classify.\n",
        "        \"\"\"\n",
        " \n",
        "        # Annotate input text using pretrained model\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "            pipeline_annotator = LightPipeline(self.pipeline_model) # Convert the pipeline to an annotator\n",
        "        else:\n",
        "            pipeline_annotator = self.pipeline_model\n",
        "\n",
        "        annotations =  pipeline_annotator.annotate(string_list)\n",
        "\n",
        "        return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "\n",
        "\n",
        "    def predict_dataframe(self, df):\n",
        "        \"\"\"Annotates the input dataframe with the classification results.\n",
        "\n",
        "        Args:\n",
        "          df : Pandas or Spark dataframe to classify (must contain a \"text\" column)\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(df, pd.DataFrame):\n",
        "            # Convert to spark dataframe for faster prediction\n",
        "            df_spark = spark.createDataFrame(df) \n",
        "        else:\n",
        "            df_spark = df\n",
        "\n",
        "        # Annotate dataframe with classification results\n",
        "        df_spark = self.pipeline_model.transform(df_spark)\n",
        "\n",
        "        #Extract sentiment score\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "          df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"Some(positive)\"].alias(\"positive\"),\n",
        "                                                                                            col(\"metadata\")[\"Some(neutral)\"].alias(\"neutral\"),\n",
        "                                                                                            col(\"metadata\")[\"Some(negative)\"].alias(\"negative\"))\n",
        "        else:\n",
        "          df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                            col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                            col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "        \n",
        "        # Extract only target and label columns\n",
        "        df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "        # Rename to result column to Predicted Sentiment\n",
        "        df_spark = df_spark.withColumnRenamed(\"result\", \"Predicted_Sentiment\")\n",
        "\n",
        "        # Convert sentiment from a list to a string\n",
        "        df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "        # Join the predictions dataframe to the scores dataframe\n",
        "        # Add temporary column index to join\n",
        "        w = Window.orderBy(monotonically_increasing_id())\n",
        "        df_spark_with_index =  df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "        df_spark_scores_with_index =  df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "        # Join the predictions and the scores in one dataframe\n",
        "        df_spark_with_index = df_spark_with_index.join(df_spark_scores_with_index,\n",
        "                                df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "                                'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "        # Remove the index column\n",
        "        df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "        # Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "        df_pandas_postprocessed = df_spark_combined.toPandas()\n",
        "\n",
        "        return df_pandas_postprocessed\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, df_pandas_postprocessed):\n",
        "        \"\"\"Computes accuracy by comparing labels of input dataframe.\n",
        "\n",
        "        Args:\n",
        "          df_pandas_postprocessed: pandas dataframe containing \"True_Sentiment\" and \"Predicted_Sentiment\" columns\n",
        "        \"\"\"\n",
        "    \n",
        "        from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "        # Compute the accuracy\n",
        "        accuracy = accuracy_score(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "        accuracy *= 100\n",
        "        classification_report = classification_report(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "\n",
        "        # Alternatively if the input is a postprocessed spark dataframe\n",
        "        # Compute accuracy by comparing each true label with predicted label\n",
        "        # accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "\n",
        "        return accuracy, classification_report"
      ],
      "metadata": {
        "id": "62AefsLpNiTB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Jz3QlAbR6wBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Brand in news article\n"
      ],
      "metadata": {
        "id": "MwBY37mRbKjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjgGRSs4MiG",
        "outputId": "ad38936e-3778-46a9-9d83-2226d7b3fe4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline, body = article\n",
        "\n",
        "brand_by_headline = brand_identifier.predict_brand(headline)\n",
        "\n",
        "# Only use article body if no brand identified in the headline\n",
        "if brand_by_headline.count() == 0:\n",
        "    brand_by_body = brand_identifier.predict_brand(body)"
      ],
      "metadata": {
        "id": "gUgFEXqubJwk",
        "outputId": "45455b4f-cb72-4e20-e894-428835de25ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|                text|Predicted_brand|\n",
            "+--------------------+---------------+\n",
            "|Google sued in US...|         Google|\n",
            "+--------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_hl = [\"Bad news for Google\", \"Tesla went bankrupt today.\"]\n",
        "brands = brand_identifier.predict_brand(list_of_hl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2fIFzbU_j_K",
        "outputId": "6f8b0bc5-2572-4c87-9451-cd6200138725"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|                text|Predicted_brand|\n",
            "+--------------------+---------------+\n",
            "| Bad news for Google|         Google|\n",
            "|Tesla went bankru...|          Tesla|\n",
            "+--------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify article using chosen pipeline"
      ],
      "metadata": {
        "id": "HoTrh-sEUeRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifier = SentimentIdentification(MODEL_NAME =  \"analyze_sentimentdl_glove_imdb\")\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # Uses https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "identifier_pretrained.predict_string_list([headline, body])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMwzvEYnPKEQ",
        "outputId": "99fb9bea-a3bd-4a49-b7ff-6c2eec989be4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n",
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'negative']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the accuracy of sentiment using the Financial News Headline Dataset"
      ],
      "metadata": {
        "id": "5GVcdPcr3Ldk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER "
      ],
      "metadata": {
        "id": "-QvbGQDaOR3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Kaggle data to Pandas dataframe and preprocess"
      ],
      "metadata": {
        "id": "QpKHFStDuQJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from Github\n",
        "NER_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/NER_test_data.csv'\n",
        "\n",
        "# Convert csv data to Pandas dataframe \n",
        "df_NER = pd.read_csv(NER_url, header=None).head(500) # 'header=None' prevents pandas eating the first row as headers\n",
        "df_NER.columns = ['Brand', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "# df_NER = df_NER.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 10\n",
        "total_num_sentences = df_NER.shape[0]\n",
        "df_NER.drop(df_NER.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Alternatively, create a preprocessed spark dataframe from csv\n",
        "from pyspark import SparkFiles\n",
        "spark.sparkContext.addFile(NER_url)\n",
        "\n",
        "# Read raw dataframe\n",
        "df_spark_org = spark.read.csv(\"file://\"+SparkFiles.get(\"NER_test_data.csv\"))\n",
        "\n",
        "# Rename columns\n",
        "df_spark_org = df_spark_org.withColumnRenamed(\"_c0\", \"Brand\").withColumnRenamed(\"_c1\", \"text\")\n",
        "df_spark_org = df_spark_org.limit(num_sentences)"
      ],
      "metadata": {
        "id": "p7fSpePI1K-G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the brand in each sentence & compute accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "_NYARSWW3-X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\" / \"ner_dl\"\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGW3Pdx9_4q7",
        "outputId": "1fc7f0da-55ca-46d5-e357-94d638064b37"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify all brands using Spark Dataframe of sentences as input "
      ],
      "metadata": {
        "id": "ehtVDL9_X5lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brand_identifier.predict_brand(df_NER)\n",
        "brand_identifier.predict_brand(df_spark_org)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKDd3hNN7-Dj",
        "outputId": "75d2c151-6c38-4017-862a-dff140445f78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|                text|Predicted_brand|\n",
            "+--------------------+---------------+\n",
            "|According to Gran...|           Gran|\n",
            "|Technopolis plans...|    Technopolis|\n",
            "|The international...|      Postimees|\n",
            "|According to the ...|        Basware|\n",
            "|FINANCING OF ASPO...|       ASPOCOMP|\n",
            "|For the last quar...|     Componenta|\n",
            "|In the third quar...|            EUR|\n",
            "+--------------------+---------------+\n",
            "\n",
            "+--------------------+---------------+\n",
            "|                text|Predicted_brand|\n",
            "+--------------------+---------------+\n",
            "|According to Gran...|           Gran|\n",
            "|Technopolis plans...|    Technopolis|\n",
            "|The international...|        Elcoteq|\n",
            "|According to the ...|        Basware|\n",
            "|FINANCING OF ASPO...|GROWTH Aspocomp|\n",
            "|For the last quar...|     Componenta|\n",
            "|In the third quar...|            EUR|\n",
            "+--------------------+---------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[text: string, Predicted_brand: string]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve speed of identification using Spark User-defined function\n",
        "dataframe_type = \"Spark\"\n",
        "\n",
        "if dataframe_type == \"Pandas\": df_spark_org = spark.createDataFrame(df_NER)  # Only keep the 'text' column\n",
        "df_spark = brand_identifier.pipeline_model.transform(df_spark_org)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pred_brand = F.udf(lambda z: get_brand(z), StringType()) # Output a string\n",
        "# spark.udf.register(\"pred_brand\", pred_brand)\n",
        "\n",
        "def get_brand(row_list):\n",
        "    if not row_list: # If the list is empty\n",
        "        return \"None\"\n",
        "\n",
        "    else:\n",
        "        # Create a pandas df with entity names and types\n",
        "        data = [[row.result, row.metadata['entity']] for row in row_list]\n",
        "        df_pd = pd.DataFrame(data, columns = ['Entity', 'Type'])\n",
        "  \n",
        "        # Filter only ORGs\n",
        "        df_pd = df_pd[df_pd[\"Type\"] == \"ORG\"]\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df_pd[\"Entity\"].value_counts() # a Pandas Series object\n",
        "        \n",
        "        # If no ORG identified in headline, return None\n",
        "        if len(ranked_df.index) == 0:\n",
        "           return \"None\"\n",
        "\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif len(ranked_df.index) == 1:\n",
        "           return ranked_df.index[0]\n",
        "\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df[0] > ranked_df[1]:\n",
        "            return ranked_df.index[0] \n",
        "\n",
        "        else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "            return random.choice([ranked_df.index[0], ranked_df.index[1]])\n",
        "\n",
        "# pred_brand_col = pred_brand(df_spark.ner_chunk)\n",
        "df_spark_combined = df_spark.withColumn('Predicted Brand', pred_brand('ner_chunk'))\n",
        "df_spark_final = df_spark_combined.select(\"Brand\", \"Predicted Brand\")\n",
        "df_spark_final.show(100)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to create ranked tables for {num_sentences} sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9smD7qJWX5X",
        "outputId": "16e534b7-b4b1-4f8f-9e25-2a2625e319c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+\n",
            "|       Brand|Predicted Brand|\n",
            "+------------+---------------+\n",
            "|        None|           Gran|\n",
            "|Technopolis |    Technopolis|\n",
            "|     Elcoteq|        Elcoteq|\n",
            "|        None|           None|\n",
            "|     Basware|        Basware|\n",
            "|    Aspocomp|       ASPOCOMP|\n",
            "|  Componenta|     Componenta|\n",
            "|        None|            EUR|\n",
            "|        None|           None|\n",
            "|        None|           None|\n",
            "+------------+---------------+\n",
            "\n",
            "2.205476760864258 seconds elapsed to create ranked tables for 10 sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the accuracy\n",
        "df_pd_post = df_spark_final.toPandas()\n",
        "\n",
        "y_true = df_pd_post['Brand'].to_numpy()\n",
        "y_pred = df_pd_post['Predicted Brand'].to_numpy()\n",
        "print(f\"The accuracy is {100*sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBnLS_2bzRZ4",
        "outputId": "1a57391f-14a9-4628-c739-f130fabf9674"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 60.0%. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment"
      ],
      "metadata": {
        "id": "zqhY6YdzDOxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Sentiment Test data"
      ],
      "metadata": {
        "id": "LA3mYD2kK2V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Kaggle data to Pandas dataframe and preprocess\n",
        "import time\n",
        "\n",
        "sentiment_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/sentiment_test_data.csv'\n",
        "\n",
        "# Store data in a Pandas Dataframe\n",
        "df_pandas = pd.read_csv(sentiment_url, header=None)\n",
        "\n",
        "# Change column names (pipelines require a \"text\" column to predict)\n",
        "df_pandas.columns = ['True_Sentiment', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "# df_pandas = df_pandas.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 100\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "print(df_pandas.shape)\n",
        "\n",
        "# Create a preprocessed spark dataframe\n",
        "from pyspark import SparkFiles\n",
        "spark.sparkContext.addFile(sentiment_url)\n",
        "\n",
        "# Read raw dataframe\n",
        "df_spark = spark.read.csv(\"file://\"+SparkFiles.get(\"sentiment_test_data.csv\"))\n",
        "\n",
        "# Rename columns\n",
        "df_spark = df_spark.withColumnRenamed(\"_c0\", \"True_Sentiment\").withColumnRenamed(\"_c1\", \"text\")\n",
        "df_spark = df_spark.limit(num_sentences)"
      ],
      "metadata": {
        "id": "nwLHDZohOPJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55559545-d981-4ae9-96f5-c2f94f179dfe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Pandas Dataframe as input"
      ],
      "metadata": {
        "id": "PJc83LMsgJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "\n",
        "# Create identifier\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "start = time.time()\n",
        "df_pandas_postprocessed = identifier_pretrained.predict_dataframe(df_pandas)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "display(df_pandas_postprocessed)\n",
        "\n",
        "# Print accuracy metrics\n",
        "accuracy, report = identifier_pretrained.compute_accuracy(df_pandas_postprocessed)\n",
        "print(accuracy)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "plG0dY_MZu5Z",
        "outputId": "fa8572f5-2c74-4f47-d3bd-b12448d6b4e9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n",
            "8.60404634475708 seconds elapsed to classify 100 sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 text True_Sentiment  \\\n",
              "0   According to Gran , the company has no plans t...        neutral   \n",
              "1   Technopolis plans to develop in stages an area...        neutral   \n",
              "2   The international electronic industry company ...       negative   \n",
              "3   With the new production plant the company woul...       positive   \n",
              "4   According to the company 's updated strategy f...       positive   \n",
              "..                                                ...            ...   \n",
              "95  Finnish financial group Aktia reports operatin...       positive   \n",
              "96  Finnish high technology provider Vaahto Group ...       positive   \n",
              "97  Net sales of Finnish food industry company L+Æ...       positive   \n",
              "98  An individual promotion also generated slightl...       positive   \n",
              "99  Biohit already services many current Genesis c...       positive   \n",
              "\n",
              "   Predicted_Sentiment     positive      neutral      negative  \n",
              "0              neutral   0.12297334   0.86686766  0.0101589905  \n",
              "1              neutral    0.4397083    0.5517359   0.008555828  \n",
              "2             negative  0.007987234  0.020264545    0.97174823  \n",
              "3             positive   0.94661206  0.041555237   0.011832709  \n",
              "4             positive   0.82584727   0.16569562   0.008457142  \n",
              "..                 ...          ...          ...           ...  \n",
              "95            positive    0.9541533   0.02044385   0.025402829  \n",
              "96            positive    0.9544416  0.024953552   0.020604838  \n",
              "97            positive    0.9560372  0.020124989   0.023837768  \n",
              "98            positive      0.94974  0.018966526   0.031293508  \n",
              "99            positive    0.9397565   0.04902275   0.011220714  \n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ed9557d-4687-4cdc-9c71-96c3b866d0bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.12297334</td>\n",
              "      <td>0.86686766</td>\n",
              "      <td>0.0101589905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.4397083</td>\n",
              "      <td>0.5517359</td>\n",
              "      <td>0.008555828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.007987234</td>\n",
              "      <td>0.020264545</td>\n",
              "      <td>0.97174823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.94661206</td>\n",
              "      <td>0.041555237</td>\n",
              "      <td>0.011832709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.82584727</td>\n",
              "      <td>0.16569562</td>\n",
              "      <td>0.008457142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Finnish financial group Aktia reports operatin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9541533</td>\n",
              "      <td>0.02044385</td>\n",
              "      <td>0.025402829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Finnish high technology provider Vaahto Group ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9544416</td>\n",
              "      <td>0.024953552</td>\n",
              "      <td>0.020604838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Net sales of Finnish food industry company L+Æ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9560372</td>\n",
              "      <td>0.020124989</td>\n",
              "      <td>0.023837768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>An individual promotion also generated slightl...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.94974</td>\n",
              "      <td>0.018966526</td>\n",
              "      <td>0.031293508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Biohit already services many current Genesis c...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9397565</td>\n",
              "      <td>0.04902275</td>\n",
              "      <td>0.011220714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ed9557d-4687-4cdc-9c71-96c3b866d0bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ed9557d-4687-4cdc-9c71-96c3b866d0bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ed9557d-4687-4cdc-9c71-96c3b866d0bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.33      1.00      0.50         1\n",
            "     neutral       0.92      0.52      0.67        21\n",
            "    positive       0.89      0.97      0.93        78\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.71      0.83      0.70       100\n",
            "weighted avg       0.89      0.88      0.87       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict using Spark Dataframe Input"
      ],
      "metadata": {
        "id": "EDnSYA1jzkNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create identifier\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "start = time.time()\n",
        "# df_pandas_postprocessed = identifier_pretrained.predict_sp_dataframe(df_spark)\n",
        "df_pandas_postprocessed = identifier_pretrained.predict_dataframe(df_spark)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "display(df_pandas_postprocessed)"
      ],
      "metadata": {
        "id": "atfuAY97ztbD",
        "outputId": "6732b226-32cc-499f-c9b7-d0f17ab63782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n",
            "11.127475500106812 seconds elapsed to classify 100 sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 text True_Sentiment  \\\n",
              "0   According to Gran , the company has no plans t...        neutral   \n",
              "1   Technopolis plans to develop in stages an area...        neutral   \n",
              "2   The international electronic industry company ...       negative   \n",
              "3   With the new production plant the company woul...       positive   \n",
              "4   According to the company 's updated strategy f...       positive   \n",
              "..                                                ...            ...   \n",
              "95  Finnish financial group Aktia reports operatin...       positive   \n",
              "96  Finnish high technology provider Vaahto Group ...       positive   \n",
              "97  Net sales of Finnish food industry company L+Æ...       positive   \n",
              "98  An individual promotion also generated slightl...       positive   \n",
              "99  Biohit already services many current Genesis c...       positive   \n",
              "\n",
              "   Predicted_Sentiment     positive      neutral      negative  \n",
              "0              neutral   0.12297334   0.86686766  0.0101589905  \n",
              "1              neutral    0.4397083    0.5517359   0.008555828  \n",
              "2             negative  0.007987234  0.020264545    0.97174823  \n",
              "3             positive   0.94661206  0.041555237   0.011832709  \n",
              "4             positive   0.82584727   0.16569562   0.008457142  \n",
              "..                 ...          ...          ...           ...  \n",
              "95            positive    0.9541533   0.02044385   0.025402829  \n",
              "96            positive    0.9544416  0.024953552   0.020604838  \n",
              "97            positive    0.9560372  0.020124989   0.023837768  \n",
              "98            positive      0.94974  0.018966526   0.031293508  \n",
              "99            positive    0.9397565   0.04902275   0.011220714  \n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd8dbae7-a81b-4d37-b05d-e15fb1003bf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.12297334</td>\n",
              "      <td>0.86686766</td>\n",
              "      <td>0.0101589905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.4397083</td>\n",
              "      <td>0.5517359</td>\n",
              "      <td>0.008555828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.007987234</td>\n",
              "      <td>0.020264545</td>\n",
              "      <td>0.97174823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.94661206</td>\n",
              "      <td>0.041555237</td>\n",
              "      <td>0.011832709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.82584727</td>\n",
              "      <td>0.16569562</td>\n",
              "      <td>0.008457142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Finnish financial group Aktia reports operatin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9541533</td>\n",
              "      <td>0.02044385</td>\n",
              "      <td>0.025402829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Finnish high technology provider Vaahto Group ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9544416</td>\n",
              "      <td>0.024953552</td>\n",
              "      <td>0.020604838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Net sales of Finnish food industry company L+Æ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9560372</td>\n",
              "      <td>0.020124989</td>\n",
              "      <td>0.023837768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>An individual promotion also generated slightl...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.94974</td>\n",
              "      <td>0.018966526</td>\n",
              "      <td>0.031293508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Biohit already services many current Genesis c...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9397565</td>\n",
              "      <td>0.04902275</td>\n",
              "      <td>0.011220714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd8dbae7-a81b-4d37-b05d-e15fb1003bf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd8dbae7-a81b-4d37-b05d-e15fb1003bf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd8dbae7-a81b-4d37-b05d-e15fb1003bf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the sentiment in each sentence one by one"
      ],
      "metadata": {
        "id": "0jQZPrKIOP3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the identifier object\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # 90.2% accuracy on 500 sentences 89.8% on 1000 sentences\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "\n",
        "\n",
        "\n",
        "preds = []\n",
        "target = []\n",
        "ignored_idxs = []\n",
        "sentiment_to_ignore = \"\" # e.g. neutral\n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Collect predicted sentiment for each headline - take three minutes to run\n",
        "for idx, hl in enumerate(df_pandas['text']):\n",
        "\n",
        "    # Only append the sentiment if it is not the sentiment to ignore (e.g. neutral)\n",
        "    target_sentiment = df_pandas[\"True_Sentiment\"][df_pandas.index[idx]]\n",
        "\n",
        "    if target_sentiment != sentiment_to_ignore:\n",
        "      preds.append(identifier.predict_string_list([hl])[0])\n",
        "    else:\n",
        "      ignored_idxs.append(idx)\n",
        "\n",
        "    # Print progress\n",
        "    if idx % 25 == 0:\n",
        "      print(f\"Classification {100*idx/num_sentences}% done.\")\n",
        "\n",
        "# Remove all ignored entries from dataset\n",
        "df_pandas.drop(df_pandas.index[ignored_idxs], inplace=True)\n",
        "\n",
        "df_pandas['Predicted_Sentiment'] = preds\n",
        "\n",
        "# Measure how long it takes\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Modify predicted labels to match with true labels\n",
        "# df = df.replace({'Predicted Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "df_pandas"
      ],
      "metadata": {
        "id": "5jFhoWw54zMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f24a4db8-8135-4525-afde-c4110f3e1003"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "Classification 0.0% done.\n",
            "Classification 83.33333333333333% done.\n",
            "2.4437243938446045 seconds elapsed to classify 30 sentences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   True_Sentiment                                               text  \\\n",
              "0         neutral  According to Gran , the company has no plans t...   \n",
              "1         neutral  Technopolis plans to develop in stages an area...   \n",
              "2        negative  The international electronic industry company ...   \n",
              "3        positive  With the new production plant the company woul...   \n",
              "4        positive  According to the company 's updated strategy f...   \n",
              "5        positive  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...   \n",
              "6        positive  For the last quarter of 2010 , Componenta 's n...   \n",
              "7        positive  In the third quarter of 2010 , net sales incre...   \n",
              "8        positive  Operating profit rose to EUR 13.1 mn from EUR ...   \n",
              "9        positive  Operating profit totalled EUR 21.1 mn , up fro...   \n",
              "10       positive  TeliaSonera TLSN said the offer is in line wit...   \n",
              "11       positive  STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMEN...   \n",
              "12       positive  A purchase agreement for 7,200 tons of gasolin...   \n",
              "13       positive  Finnish Talentum reports its operating profit ...   \n",
              "14       positive  Clothing retail chain Sepp+Æl+Æ 's sales incre...   \n",
              "15       positive  Consolidated net sales increased 16 % to reach...   \n",
              "16       positive  Foundries division reports its sales increased...   \n",
              "17       positive  HELSINKI ( AFX ) - Shares closed higher , led ...   \n",
              "18       positive  Incap Contract Manufacturing Services Pvt Ltd ...   \n",
              "19       positive  Its board of directors will propose a dividend...   \n",
              "20       positive  Lifetree was founded in 2000 , and its revenue...   \n",
              "21       positive  ( Filippova ) A trilateral agreement on invest...   \n",
              "22       positive  MegaFon 's subscriber base increased 16.1 % in...   \n",
              "23       positive  Net income from life insurance doubled to EUR ...   \n",
              "24       positive  Net sales increased to EUR193 .3 m from EUR179...   \n",
              "25       positive  Net sales surged by 18.5 % to EUR167 .8 m. Tel...   \n",
              "26       positive  Nordea Group 's operating profit increased in ...   \n",
              "27       positive  Operating profit for the nine-month period inc...   \n",
              "28       positive  Operating profit for the nine-month period inc...   \n",
              "29       positive  Operating profit for the three-month period in...   \n",
              "\n",
              "   Predicted_Sentiment  \n",
              "0              neutral  \n",
              "1              neutral  \n",
              "2             negative  \n",
              "3             positive  \n",
              "4             positive  \n",
              "5             positive  \n",
              "6             positive  \n",
              "7             positive  \n",
              "8             positive  \n",
              "9             positive  \n",
              "10            positive  \n",
              "11            positive  \n",
              "12             neutral  \n",
              "13            positive  \n",
              "14            positive  \n",
              "15            positive  \n",
              "16            positive  \n",
              "17            positive  \n",
              "18            positive  \n",
              "19            positive  \n",
              "20            positive  \n",
              "21             neutral  \n",
              "22            positive  \n",
              "23            positive  \n",
              "24            positive  \n",
              "25            positive  \n",
              "26            positive  \n",
              "27            positive  \n",
              "28            positive  \n",
              "29            positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79ec84ad-feab-4267-8a47-a518d6a81b1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>positive</td>\n",
              "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>positive</td>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>positive</td>\n",
              "      <td>TeliaSonera TLSN said the offer is in line wit...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>positive</td>\n",
              "      <td>STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMEN...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>positive</td>\n",
              "      <td>A purchase agreement for 7,200 tons of gasolin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>positive</td>\n",
              "      <td>Finnish Talentum reports its operating profit ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>positive</td>\n",
              "      <td>Clothing retail chain Sepp+Æl+Æ 's sales incre...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>positive</td>\n",
              "      <td>Consolidated net sales increased 16 % to reach...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>positive</td>\n",
              "      <td>Foundries division reports its sales increased...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>positive</td>\n",
              "      <td>HELSINKI ( AFX ) - Shares closed higher , led ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>positive</td>\n",
              "      <td>Incap Contract Manufacturing Services Pvt Ltd ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>positive</td>\n",
              "      <td>Its board of directors will propose a dividend...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>positive</td>\n",
              "      <td>Lifetree was founded in 2000 , and its revenue...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>positive</td>\n",
              "      <td>( Filippova ) A trilateral agreement on invest...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>positive</td>\n",
              "      <td>MegaFon 's subscriber base increased 16.1 % in...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>positive</td>\n",
              "      <td>Net income from life insurance doubled to EUR ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>positive</td>\n",
              "      <td>Net sales increased to EUR193 .3 m from EUR179...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>positive</td>\n",
              "      <td>Net sales surged by 18.5 % to EUR167 .8 m. Tel...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>positive</td>\n",
              "      <td>Nordea Group 's operating profit increased in ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit for the nine-month period inc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit for the nine-month period inc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit for the three-month period in...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79ec84ad-feab-4267-8a47-a518d6a81b1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79ec84ad-feab-4267-8a47-a518d6a81b1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79ec84ad-feab-4267-8a47-a518d6a81b1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure the Accuracy"
      ],
      "metadata": {
        "id": "OugF9Z-6t0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = df_pandas_postprocessed['True_Sentiment'].to_numpy()\n",
        "y_pred = df_pandas_postprocessed['Predicted_Sentiment'].to_numpy()\n",
        "\n",
        "\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "\n",
        "# Compute classification metrics - poor accuracy\n",
        "print(classification_report(y_true, y_pred))#, target_names=target_names))"
      ],
      "metadata": {
        "id": "JiLV0Glo_Kzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bccad55b-5448-4aea-820b-844fc2802219"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 93.33333333333333%. \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00         1\n",
            "     neutral       0.50      1.00      0.67         2\n",
            "    positive       1.00      0.93      0.96        27\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.83      0.98      0.88        30\n",
            "weighted avg       0.97      0.93      0.94        30\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BDijGosdPGzW",
        "-5m65UosNdY5",
        "HoTrh-sEUeRf"
      ],
      "name": "John Snow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}