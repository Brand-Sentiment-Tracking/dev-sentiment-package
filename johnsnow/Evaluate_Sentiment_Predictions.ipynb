{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluate Sentiment Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOF58Uv6M7wE42yTwA4Egpi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/dev-sentiment-package/blob/main/johnsnow/Evaluate_Sentiment_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Sentiment Predictions\n"
      ],
      "metadata": {
        "id": "Pv7HwRRJf_ht"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDySD2IHU9di"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Imports from prod package\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.base import DocumentAssembler\n",
        "from sparknlp.annotator import Tokenizer, BertForSequenceClassification\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "# Import functions to manipulate dataframe\n",
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "from pyspark.sql.types import StringType, ArrayType\n",
        "from pyspark.ml import Pipeline\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "poITcnROp9Hx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bnOW8Mt7VH97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c29ba1e-4597-4af0-a626-705be9719855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.3\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "# Spark dataframe manipulation imports\n",
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "\n",
        "# spark = sparknlp.start(gpu=False)\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Sentiment Prediction Class"
      ],
      "metadata": {
        "id": "ibr6lbDzgX8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the spark udf function outside the class\n",
        "def append_sentiment(pair_list, sentiment):\n",
        "    \"\"\"Append sentiment to each entry in pred brand list. \"\"\"\n",
        "\n",
        "    for pair in pair_list:\n",
        "        pair.append(sentiment)\n",
        "\n",
        "    return pair_list\n",
        "\n",
        "\n",
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "        spark = sparknlp.start()\n",
        "\n",
        "        # Create a custom pipline if requested\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":  # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "            document_assembler = DocumentAssembler() \\\n",
        "                .setInputCol('text') \\\n",
        "                .setOutputCol('document')\n",
        "\n",
        "            tokenizer = Tokenizer() \\\n",
        "                .setInputCols(['document']) \\\n",
        "                .setOutputCol('token')\n",
        "\n",
        "            sequenceClassifier = BertForSequenceClassification \\\n",
        "                .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                .setInputCols(['token', 'document']) \\\n",
        "                .setOutputCol('class') \\\n",
        "                .setCaseSensitive(True) \\\n",
        "                .setMaxSentenceLength(512)\n",
        "\n",
        "            pipeline = Pipeline(stages=[\n",
        "                document_assembler,\n",
        "                tokenizer,\n",
        "                sequenceClassifier\n",
        "            ])\n",
        "\n",
        "            self.pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))\n",
        "\n",
        "        else:\n",
        "            self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang='en')\n",
        "\n",
        "    def predict_dataframe(self, df):\n",
        "        \"\"\"Annotates the input dataframe with the classification results.\n",
        "        Args:\n",
        "          df : Pandas or Spark dataframe to classify (must contain a \"text\" column)\n",
        "        \"\"\"\n",
        "        spark = sparknlp.start()\n",
        "\n",
        "        if isinstance(df, pd.DataFrame):\n",
        "            # Convert to spark dataframe for faster prediction\n",
        "            df_spark = spark.createDataFrame(df)\n",
        "        else:\n",
        "            df_spark = df\n",
        "\n",
        "        # Annotate dataframe with classification results\n",
        "        df_spark = self.pipeline_model.transform(df_spark)\n",
        "\n",
        "        # Extract sentiment score\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "            df_spark_scores = df_spark.select(\n",
        "                explode(col(\"class.metadata\")).alias(\"metadata\")) \\\n",
        "                .select(col(\"metadata\")[\"Some(positive)\"].alias(\"positive\"),\n",
        "                        col(\"metadata\")[\"Some(neutral)\"].alias(\"neutral\"),\n",
        "                        col(\"metadata\")[\"Some(negative)\"].alias(\"negative\"))\n",
        "        else:\n",
        "            df_spark_scores = df_spark.select(\n",
        "                explode(col(\"class.metadata\")).alias(\"metadata\")) \\\n",
        "                .select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                        col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                        col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "\n",
        "        df_spark_scores = df_spark_scores.withColumn(\"score\", col(\"positive\") - col(\"negative\"))\n",
        "\n",
        "        # Extract only target and label columns\n",
        "        df_spark = df_spark.select(\"text\", \"source_domain\", \"date_publish\", \"language\", \"Predicted_Entity\", \"class.result\")  # This is to run main.py\n",
        "\n",
        "        # Rename to result column to Predicted Sentiment\n",
        "        df_spark = df_spark.withColumnRenamed(\"result\", \"Predicted_Sentiment\")\n",
        "\n",
        "        # Convert sentiment from a list to a string\n",
        "        df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "        # Join the predictions dataframe to the scores dataframe\n",
        "        # Add temporary column index to join\n",
        "        w = Window.orderBy(monotonically_increasing_id())\n",
        "        df_spark_with_index = df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "        df_spark_scores_with_index = df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "        # Join the predictions and the scores in one dataframe\n",
        "        df_spark_with_index = df_spark_with_index.join(\n",
        "            df_spark_scores_with_index,\n",
        "            df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "            'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "        # Remove the index column\n",
        "        df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "        # Append sentiment to each entry in pred brand list\n",
        "        append_sent = F.udf(lambda x, y: append_sentiment(x, y), ArrayType(ArrayType(StringType())))  # Output a list of lists\n",
        "        df_spark_combined = df_spark_combined.withColumn('Predicted_Entity_and_Sentiment', append_sent('Predicted_Entity', 'Predicted_Sentiment'))\n",
        "\n",
        "        # Keep positive/neutral/negative probabilities in the output spark df\n",
        "        df_spark_combined = df_spark_combined.drop('Predicted_Entity', 'Predicted_Sentiment')\n",
        "\n",
        "        return df_spark_combined\n",
        "\n",
        "    def predict_and_evaluate(self, df_spark):\n",
        "        \"\"\"Computes accuracy by comparing labels of input dataframe.\n",
        "\n",
        "        Args:\n",
        "          df_spark: spark dataframe containing \"text\" and \"True_Sentiment\" column\n",
        "        \"\"\"\n",
        "    \n",
        "        from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "        # Annotate dataframe with classification results\n",
        "        df_spark = self.pipeline_model.transform(df_spark)\n",
        "\n",
        "\n",
        "        # Extract only necessary columns\n",
        "        if self.MODEL_NAME == \"custom_pipeline\" or self.MODEL_NAME == \"classifierdl_bertwiki_finance_sentiment_pipeline\":\n",
        "              df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "        else:\n",
        "              df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"sentiment.result\")\n",
        "                                   \n",
        "        # Rename to result column to Predicted Sentiment\n",
        "        df_spark = df_spark.withColumnRenamed(\"result\", \"Predicted_Sentiment\")\n",
        "\n",
        "        # Convert sentiment from a list to a string\n",
        "        df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "        # Convert to pandas to use sklearn functions\n",
        "        df_pandas_postprocessed = df_spark.toPandas()\n",
        "\n",
        "        # Replace if abbreviated\n",
        "        # Modify predicted labels to match with true labels\n",
        "        df_pandas_postprocessed = df_pandas_postprocessed.replace({'Predicted_Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "        # Compute the accuracy\n",
        "        accuracy = accuracy_score(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "        accuracy *= 100\n",
        "        classification_report = classification_report(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "\n",
        "        # Alternatively if the input is a postprocessed spark dataframe\n",
        "        # Compute accuracy by comparing each true label with predicted label\n",
        "        # accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "\n",
        "        return accuracy, classification_report, df_pandas_postprocessed\n"
      ],
      "metadata": {
        "id": "7_mvi2Xzgbo6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Extracted Dataset"
      ],
      "metadata": {
        "id": "m7oPkWGjtcJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_url_2 = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/dev-sentiment-package/main/data/unlabelled_test_en_10_labels.csv' # owr extracted data\n",
        "sentiment_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/dev-sentiment-package/main/data/labelled_1.csv'\n",
        "\n",
        "num_sentences = 500 # Total is \n",
        "\n",
        "# # Store data in a Pandas Dataframe\n",
        "cols_to_read = ['text',\"sentiment (Max's take)\"]\n",
        "df_pandas = pd.read_csv(sentiment_url, usecols=cols_to_read)\n",
        "\n",
        "# Rename sentiment to True_Sentiment\n",
        "df_pandas.rename(columns={\"sentiment (Max's take)\":\"True_Sentiment\"},inplace=True)\n",
        "\n",
        "# # Make dataset smaller for faster runtime\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "# Replace 1, 2 , 3 with negative, neutral, positive\n",
        "df_pandas[\"True_Sentiment\"].replace({1.0: \"negative\", 2.0: \"neutral\", 3.0: \"positive\"}, inplace=True)\n",
        "\n",
        "\n",
        "# Fill the NaN entires with zeros\n",
        "# df_pandas['date_publish'] = df_pandas['date_publish'].fillna(0.0)\n",
        "\n",
        "display(df_pandas)\n",
        "\n",
        "# # Convert to spark dataframe  \n",
        "df_spark = spark.createDataFrame(df_pandas)\n",
        "\n",
        "# df_spark.show()\n",
        "\n",
        "# # # Create a preprocessed spark dataframe\n",
        "# from pyspark import SparkFiles\n",
        "# spark.sparkContext.addFile(sentiment_url)\n",
        "\n",
        "# # Read raw dataframe\n",
        "# df_spark = spark.read.option(\"header\",\"true\").option(\"multiline\",\"true\").csv(\"file://\"+SparkFiles.get(\"unlabelled_test_en_10_labels.csv\"))\n",
        "\n",
        "# df_spark = df_spark.select(\"text\", \"sentiment\")\n",
        "\n",
        "# # Rename columns\n",
        "# df_spark = df_spark.withColumnRenamed(\"sentiment\", \"True_Sentiment\")\n",
        "\n",
        "# df_spark = df_spark.limit(num_sentences)\n",
        "\n",
        "# df_spark.show()\n"
      ],
      "metadata": {
        "id": "YTmQSp28qAK-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8daf5ea0-dae1-4651-aacb-59e7089a0fc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  text True_Sentiment\n",
              "0    RYU Apparel Brings Customer Care Services In-h...       positive\n",
              "1    AMREP Co. (NYSE:AXR) Director Edward B. Cloues...        neutral\n",
              "2    Johnson arrives in India to meet Modi, seek ec...        neutral\n",
              "3                      Remembering Bearden High School        neutral\n",
              "4    ‘My body is here, but my soul, mind and everyt...        neutral\n",
              "..                                                 ...            ...\n",
              "495  I’m a McDonald’s superfan so tried out ALL the...       negative\n",
              "496  It's too early to compare Afena-Gyan to me - A...        neutral\n",
              "497  US-Saudi relations nearing 'breaking point' --...       negative\n",
              "498  2022 BMW 7 Series revealed with electric drive...        neutral\n",
              "499          Driver injured in I-79 bucket truck crash       negative\n",
              "\n",
              "[500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52124b90-2556-44e6-b07b-018c1f571419\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RYU Apparel Brings Customer Care Services In-h...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMREP Co. (NYSE:AXR) Director Edward B. Cloues...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Johnson arrives in India to meet Modi, seek ec...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Remembering Bearden High School</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‘My body is here, but my soul, mind and everyt...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>I’m a McDonald’s superfan so tried out ALL the...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>It's too early to compare Afena-Gyan to me - A...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>US-Saudi relations nearing 'breaking point' --...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>2022 BMW 7 Series revealed with electric drive...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Driver injured in I-79 bucket truck crash</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52124b90-2556-44e6-b07b-018c1f571419')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52124b90-2556-44e6-b07b-018c1f571419 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52124b90-2556-44e6-b07b-018c1f571419');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict the sentiment"
      ],
      "metadata": {
        "id": "fo_uuujCpBs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the sentiment classifier object"
      ],
      "metadata": {
        "id": "koHDKU5HpNoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "identifier_pretrained = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"analyze_sentimentdl_glove_imdb\") \n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"analyze_sentimentdl_use_imdb\")\n",
        "# identifier_pretrained = SentimentIdentification(MODEL_NAME = \"analyze_sentimentdl_use_twitter\")\n",
        "\n",
        "# Classification reports\n",
        "\n",
        "# Custom_pipeline:\n",
        "\n",
        "# 75.4\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     negative       0.48      0.51      0.49        65\n",
        "#      neutral       0.83      0.87      0.85       385\n",
        "#     positive       0.34      0.20      0.25        50\n",
        "\n",
        "#     accuracy                           0.75       500\n",
        "#    macro avg       0.55      0.53      0.53       500\n",
        "# weighted avg       0.74      0.75      0.74       500\n",
        "\n",
        "# classifierdl_bertwiki_finance_sentiment_pipeline:\n",
        "\n",
        "# 76.2\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     negative       0.51      0.34      0.41        65\n",
        "#      neutral       0.83      0.88      0.86       385\n",
        "#     positive       0.39      0.40      0.40        50\n",
        "\n",
        "#     accuracy                           0.76       500\n",
        "#    macro avg       0.58      0.54      0.55       500\n",
        "# weighted avg       0.75      0.76      0.75       500\n",
        "\n",
        "# analyze_sentimentdl_glove_imdb:\n",
        "\n",
        "# 18.6\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     negative       0.22      0.65      0.32        65\n",
        "#      neutral       0.76      0.03      0.06       385\n",
        "#     positive       0.13      0.76      0.22        50\n",
        "\n",
        "#     accuracy                           0.19       500\n",
        "#    macro avg       0.37      0.48      0.20       500\n",
        "# weighted avg       0.63      0.19      0.11       500\n",
        "\n",
        "# analyze_sentimentdl_use_imdb:\n",
        "\n",
        "# 15.8\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     negative       0.30      0.62      0.40        65\n",
        "#      neutral       0.00      0.00      0.00       385\n",
        "#     positive       0.11      0.78      0.19        50\n",
        "\n",
        "#     accuracy                           0.16       500\n",
        "#    macro avg       0.13      0.47      0.20       500\n",
        "# weighted avg       0.05      0.16      0.07       500\n",
        "\n",
        "# analyze_sentimentdl_use_twitter:\n",
        "\n",
        "# 18.6\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     negative       0.21      0.83      0.34        65\n",
        "#      neutral       0.92      0.03      0.06       385\n",
        "#     positive       0.12      0.56      0.20        50\n",
        "\n",
        "#     accuracy                           0.19       500\n",
        "#    macro avg       0.42      0.47      0.20       500\n",
        "# weighted avg       0.75      0.19      0.11       500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8JrAVVtpSJ9",
        "outputId": "5ce8808b-137e-48b4-9e8f-4b518dba5675"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute evaluation metrics\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FsFqzM6MJIGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print accuracy metrics\n",
        "\n",
        "start = time.time()\n",
        "accuracy, report, df_pandas_postprocessed = identifier_pretrained.predict_and_evaluate(df_spark)\n",
        "end = time.time()\n",
        "\n",
        "display(df_pandas_postprocessed)\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to predict and evaluate {num_sentences} sentences.\")\n",
        "\n",
        "print(accuracy)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "RPq2PE76pGRi",
        "outputId": "464f8db5-98b9-4e39-e292-59e8dc19c496"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  text True_Sentiment  \\\n",
              "0    RYU Apparel Brings Customer Care Services In-h...       positive   \n",
              "1    AMREP Co. (NYSE:AXR) Director Edward B. Cloues...        neutral   \n",
              "2    Johnson arrives in India to meet Modi, seek ec...        neutral   \n",
              "3                      Remembering Bearden High School        neutral   \n",
              "4    ‘My body is here, but my soul, mind and everyt...        neutral   \n",
              "..                                                 ...            ...   \n",
              "495  I’m a McDonald’s superfan so tried out ALL the...       negative   \n",
              "496  It's too early to compare Afena-Gyan to me - A...        neutral   \n",
              "497  US-Saudi relations nearing 'breaking point' --...       negative   \n",
              "498  2022 BMW 7 Series revealed with electric drive...        neutral   \n",
              "499          Driver injured in I-79 bucket truck crash       negative   \n",
              "\n",
              "    Predicted_Sentiment  \n",
              "0               neutral  \n",
              "1               neutral  \n",
              "2               neutral  \n",
              "3               neutral  \n",
              "4               neutral  \n",
              "..                  ...  \n",
              "495             neutral  \n",
              "496             neutral  \n",
              "497             neutral  \n",
              "498             neutral  \n",
              "499            negative  \n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9aabed7-7093-408a-8d3b-6f0437b0dbe1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RYU Apparel Brings Customer Care Services In-h...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMREP Co. (NYSE:AXR) Director Edward B. Cloues...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Johnson arrives in India to meet Modi, seek ec...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Remembering Bearden High School</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‘My body is here, but my soul, mind and everyt...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>I’m a McDonald’s superfan so tried out ALL the...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>It's too early to compare Afena-Gyan to me - A...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>US-Saudi relations nearing 'breaking point' --...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>2022 BMW 7 Series revealed with electric drive...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Driver injured in I-79 bucket truck crash</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9aabed7-7093-408a-8d3b-6f0437b0dbe1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9aabed7-7093-408a-8d3b-6f0437b0dbe1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9aabed7-7093-408a-8d3b-6f0437b0dbe1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.832666158676147 seconds elapsed to predict and evaluate 500 sentences.\n",
            "75.4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.48      0.51      0.49        65\n",
            "     neutral       0.83      0.87      0.85       385\n",
            "    positive       0.34      0.20      0.25        50\n",
            "\n",
            "    accuracy                           0.75       500\n",
            "   macro avg       0.55      0.53      0.53       500\n",
            "weighted avg       0.74      0.75      0.74       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write postprocessed dataframe to csv file\n",
        "df_pandas_postprocessed.to_csv('./postprocessed_data.csv')  "
      ],
      "metadata": {
        "id": "lzpusE7cVpAR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate from file"
      ],
      "metadata": {
        "id": "Rh5nDZCRXQ1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Read csv file with both labels and prediction and compute evaluation metrics\n",
        "df_pandas_labelled = pd.read_csv('./postprocessed_data.csv')\n",
        "\n",
        "# Rename columns if necessary\n",
        "df_pandas_labelled.rename(columns={\"True_Sentiment\":\"True_Sentiment\", \"Predcited_Sentiment\":\"Predicted_Sentiment\"},inplace=True)\n",
        "\n",
        "# Compute the evaluation metrics\n",
        "accuracy = accuracy_score(df_pandas_labelled[\"True_Sentiment\"], df_pandas_labelled[\"Predicted_Sentiment\"])\n",
        "accuracy *= 100\n",
        "classification_report = classification_report(df_pandas_labelled[\"True_Sentiment\"], df_pandas_labelled[\"Predicted_Sentiment\"])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUdIuiW0XT8C",
        "outputId": "78489267-f136-4c44-908d-c9cd290e7103"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 18.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.21      0.83      0.34        65\n",
            "     neutral       0.92      0.03      0.06       385\n",
            "    positive       0.12      0.56      0.20        50\n",
            "\n",
            "    accuracy                           0.19       500\n",
            "   macro avg       0.42      0.47      0.20       500\n",
            "weighted avg       0.75      0.19      0.11       500\n",
            "\n"
          ]
        }
      ]
    }
  ]
}