{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Package_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHe6Av80ZaO2YEXgsSyyAE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/dev-sentiment-package/blob/main/johnsnow/Package_notebook_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "H3iAiQaqa6mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display\n",
        "\n",
        "\n",
        "import nltk.data\n",
        "import os\n",
        "import json\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import sparknlp\n",
        "import pandas as pd\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType\n",
        "import pyspark.sql.functions as F\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "import sparknlp\n",
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "# from tabulate import tabulate\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "# Import functions to manipulate dataframe\n",
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "from pyspark import SparkFiles\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "import time\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "f4KLUARmW98i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604b697e-defc-44e1-c201-c9c8c16a869b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 72 kB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 44.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip data"
      ],
      "metadata": {
        "id": "_RQ6wh8ha3bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# before next step, upload \"cc_download_articles.zip\" to your google drive root folder\n",
        "# !unzip ./drive/MyDrive/cc_download_articles.zip -d ./drive/MyDrive/group_nlp_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEHoOpjyaHGo",
        "outputId": "9a35ef7b-fa6b-43a4-e444-9c053c58a108"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_folder = \"./drive/MyDrive/group_nlp_data/cc_download_articles/\""
      ],
      "metadata": {
        "id": "RmB42tJZbOfL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Extraction Class"
      ],
      "metadata": {
        "id": "kcXEAInTWeH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ArticleExtraction:\n",
        "    def __init__(self):\n",
        "        self.headlines = []\n",
        "\n",
        "    def import_one_article(self, filepath):\n",
        "\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            article = f.read().decode('utf-8')\n",
        "\n",
        "        return article\n",
        "\n",
        "    def import_one_headline_json(self, filepath):\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.headlines.append(data['title'])\n",
        "\n",
        "    def article_to_sentences(self, article):\n",
        "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "        return '\\n-----\\n'.join(tokenizer.tokenize(article))\n",
        "\n",
        "    def import_folder_headlines(self, folderpath):\n",
        "        for filename in os.listdir(folderpath):\n",
        "            filepath = os.path.join(folderpath, filename)\n",
        "            self.import_one_headline_json(filepath)\n",
        "        return self.headlines"
      ],
      "metadata": {
        "id": "DGrHf-CRWpVi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Brand Identification Class"
      ],
      "metadata": {
        "id": "nGphe0SvWgY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The spark udf function that has to be defined outside the class\n",
        "def get_brand(row_list):\n",
        "    if not row_list: # If the list is empty\n",
        "        return \"None\"\n",
        "\n",
        "    else:\n",
        "        # Create a pandas df with entity names and types\n",
        "        data = [[row.result, row.metadata['entity']] for row in row_list]\n",
        "        df_pd = pd.DataFrame(data, columns = ['Entity', 'Type'])\n",
        "      \n",
        "        # Filter only ORGs\n",
        "        df_pd = df_pd[df_pd[\"Type\"] == \"ORG\"]\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df_pd[\"Entity\"].value_counts() # a Pandas Series object\n",
        "            \n",
        "        # If no ORG identified in headline, return None\n",
        "        if len(ranked_df.index) == 0:\n",
        "           return \"None\"\n",
        "\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif len(ranked_df.index) == 1:\n",
        "           return ranked_df.index[0]\n",
        "\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df[0] > ranked_df[1]:\n",
        "            return ranked_df.index[0] \n",
        "\n",
        "        else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "            return random.choice([ranked_df.index[0], ranked_df.index[1]])\n",
        "            # TO DO: break even - Wikidata for article body #\n",
        "\n",
        "\n",
        "            \n",
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "        spark = sparknlp.start()\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text') # An empty df with column name \"text\"\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def predict_brand(self, text): # text could be a pandas dataframe or a Spark dataframe (both with a column \"text\"), a list of strings or a single string\n",
        "        # Run the pipeline for the text\n",
        "        spark = sparknlp.start()\n",
        "        \n",
        "        if isinstance(text, pd.DataFrame): text_df = spark.createDataFrame(text) # If input a pandas dataframe\n",
        "        elif isinstance(text, list): text_df = spark.createDataFrame(pd.DataFrame({'text': text})) # If input a list of strings\n",
        "        elif isinstance(text, str): text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index=[0])) # If input a single string\n",
        "        else: text_df = text\n",
        "\n",
        "        df_spark = self.pipeline_model.transform(text_df) \n",
        "\n",
        "        # Improve speed of identification using Spark User-defined function\n",
        "        pred_brand = F.udf(lambda z: get_brand(z), StringType()) # Output a string\n",
        "        # spark.udf.register(\"pred_brand\", pred_brand)\n",
        "\n",
        "        df_spark_combined = df_spark.withColumn('Predicted_Brand', pred_brand('ner_chunk'))\n",
        "        df_spark_combined = df_spark_combined.select(\"text\", \"Predicted_Brand\")\n",
        "        # df_spark_combined.show(100)\n",
        "\n",
        "        # Remove all rows with no brands detected\n",
        "        df_spark_final=df_spark_combined.filter(df_spark_combined.Predicted_Brand != 'None')\n",
        "        df_spark_final.show(100)\n",
        "\n",
        "        return df_spark_final"
      ],
      "metadata": {
        "id": "Lm6NlgivWuQ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Sentiment Class"
      ],
      "metadata": {
        "id": "WOMaiwMYWj1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "        spark = sparknlp.start()\n",
        "\n",
        "          # Create a custom pipline if requested\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "            document_assembler = DocumentAssembler() \\\n",
        "                .setInputCol('text') \\\n",
        "                .setOutputCol('document')\n",
        "\n",
        "            tokenizer = Tokenizer() \\\n",
        "                .setInputCols(['document']) \\\n",
        "                .setOutputCol('token')\n",
        "\n",
        "            sequenceClassifier = BertForSequenceClassification \\\n",
        "                  .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                  .setInputCols(['token', 'document']) \\\n",
        "                  .setOutputCol('class') \\\n",
        "                  .setCaseSensitive(True) \\\n",
        "                  .setMaxSentenceLength(512)\n",
        "\n",
        "            pipeline = Pipeline(stages=[\n",
        "                document_assembler,\n",
        "                tokenizer,\n",
        "                sequenceClassifier\n",
        "            ])\n",
        "\n",
        "            self.pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))\n",
        "\n",
        "        else:\n",
        "            self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "    def predict_dataframe(self, df):\n",
        "        \"\"\"Annotates the input dataframe with the classification results.\n",
        "        Args:\n",
        "          df : Pandas or Spark dataframe to classify (must contain a \"text\" column)\n",
        "        \"\"\"\n",
        "        spark = sparknlp.start()\n",
        "        \n",
        "        if isinstance(df, pd.DataFrame):\n",
        "            # Convert to spark dataframe for faster prediction\n",
        "            df_spark = spark.createDataFrame(df) \n",
        "        else:\n",
        "            df_spark = df\n",
        "\n",
        "        # Annotate dataframe with classification results\n",
        "        df_spark = self.pipeline_model.transform(df_spark)\n",
        "\n",
        "        # Extract sentiment score\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "          df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"Some(positive)\"].alias(\"positive\"),\n",
        "                                                                                            col(\"metadata\")[\"Some(neutral)\"].alias(\"neutral\"),\n",
        "                                                                                            col(\"metadata\")[\"Some(negative)\"].alias(\"negative\"))\n",
        "        else:\n",
        "          df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                            col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                            col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "        \n",
        "\n",
        "        df_spark_scores = df_spark_scores.withColumn(\"score\", col(\"positive\")-col(\"negative\"))\n",
        "\n",
        "        # Extract only target and label columns\n",
        "        # df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "        df_spark = df_spark.select(\"text\", \"Predicted_Brand\", \"class.result\") # This is to run main.py\n",
        "\n",
        "        # Rename to result column to Predicted Sentiment\n",
        "        df_spark = df_spark.withColumnRenamed(\"result\", \"Predicted_Sentiment\")\n",
        "\n",
        "        # Convert sentiment from a list to a string\n",
        "        df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "        # Join the predictions dataframe to the scores dataframe\n",
        "        # Add temporary column index to join\n",
        "        w = Window.orderBy(monotonically_increasing_id())\n",
        "        df_spark_with_index =  df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "        df_spark_scores_with_index =  df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "        # Join the predictions and the scores in one dataframe\n",
        "        df_spark_with_index = df_spark_with_index.join(df_spark_scores_with_index,\n",
        "                                df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "                                'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "        # Remove the index column\n",
        "        df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "        # Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "        # df_pandas_postprocessed = df_spark_combined.toPandas()\n",
        "\n",
        "        df_spark_combined.show(100)\n",
        "        \n",
        "        # return df_pandas_postprocessed\n",
        "        return df_spark_combined\n",
        "\n",
        "\n",
        "    def predict_string_list(self, string_list):\n",
        "        \"\"\"Predicts sentiment of the input list of strings.\n",
        "        Args:\n",
        "          string_list: List of strings to classify.\n",
        "        \"\"\"\n",
        " \n",
        "        # Annotate input text using pretrained model\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\":\n",
        "            pipeline_annotator = LightPipeline(self.pipeline_model) # Convert the pipeline to an annotator\n",
        "        else:\n",
        "            pipeline_annotator = self.pipeline_model\n",
        "\n",
        "        annotations =  pipeline_annotator.annotate(string_list)\n",
        "\n",
        "        return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, df_pandas_postprocessed):\n",
        "        \"\"\"Computes accuracy by comparing labels of input dataframe.\n",
        "        Args:\n",
        "          df_pandas_postprocessed: pandas dataframe containing \"True_Sentiment\" and \"Predicted_Sentiment\" columns\n",
        "        \"\"\"\n",
        "    \n",
        "        from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "        # Compute the accuracy\n",
        "        accuracy = accuracy_score(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "        accuracy *= 100\n",
        "        classification_report = classification_report(df_pandas_postprocessed[\"True_Sentiment\"], df_pandas_postprocessed[\"Predicted_Sentiment\"])\n",
        "\n",
        "        # Alternatively if the input is a postprocessed spark dataframe\n",
        "        # Compute accuracy by comparing each true label with predicted label\n",
        "        # accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "\n",
        "        return accuracy, classification_report"
      ],
      "metadata": {
        "id": "4SjlnIKwW4pN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run test"
      ],
      "metadata": {
        "id": "ol4k_sIGWmQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "# Define brand and sentiment identifier objects\n",
        "brand_identifier = BrandIdentification(\"ner_dl_bert\")\n",
        "# sentimentiser = SentimentIdentification(MODEL_NAME = \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "sentimentiser = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "article_extractor = ArticleExtraction()\n",
        "\n",
        "list_of_headlines = article_extractor.import_folder_headlines(articles_folder + 'cyprus-mail.com') #www.cnn.com\n",
        "\n",
        "# Predict and append extracted brands\n",
        "brand_spark_df = brand_identifier.predict_brand(list_of_headlines)\n",
        "\n",
        "# Predict and append sentiment and score\n",
        "spark_df_final = sentimentiser.predict_dataframe(brand_spark_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww9Vo9liXVYy",
        "outputId": "3ebb969c-c331-4294-c45a-9e81d1f747d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n",
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n",
            "+--------------------+--------------------+\n",
            "|                text|     Predicted_Brand|\n",
            "+--------------------+--------------------+\n",
            "|Cyprus Mail News ...|Cyprus Mail News ...|\n",
            "|Man United spoil ...|          Man United|\n",
            "|APOEL face Olympi...|          Olympiacos|\n",
            "|Cabinet reappoint...|               CySEC|\n",
            "|UEFA keeps it in ...|                UEFA|\n",
            "|Geeks rule at Cyp...|      CyprusComicCon|\n",
            "|AEK stranded in C...|                 AEK|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+-------------------+-----------+----------+-----------+--------------------+\n",
            "|                text|     Predicted_Brand|Predicted_Sentiment|   positive|   neutral|   negative|               score|\n",
            "+--------------------+--------------------+-------------------+-----------+----------+-----------+--------------------+\n",
            "|Cyprus Mail News ...|Cyprus Mail News ...|            neutral| 0.03859538|0.92489934|0.036505282|0.002090097999999...|\n",
            "|Man United spoil ...|            West Ham|            neutral| 0.18306758| 0.8001094|0.016823035| 0.16624454500000002|\n",
            "|APOEL face Olympi...|          Olympiacos|            neutral|0.054285355| 0.9071312| 0.03858344|0.015701915000000004|\n",
            "|Cabinet reappoint...|               CySEC|            neutral|0.045380317| 0.9248033|0.029816337|0.015563980000000005|\n",
            "|UEFA keeps it in ...|                UEFA|            neutral|0.037894398| 0.9407692|0.021336425|0.016557973000000004|\n",
            "|Geeks rule at Cyp...|      CyprusComicCon|            neutral|0.022995396| 0.9111386| 0.06586602|-0.04287062399999...|\n",
            "|AEK stranded in C...|                 AEK|           negative|  0.0213757|0.20137864| 0.77724564|         -0.75586994|\n",
            "+--------------------+--------------------+-------------------+-----------+----------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display results nicely"
      ],
      "metadata": {
        "id": "-__tmDz--wyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spark_df_final.show()\n",
        "\n",
        "df_pandas_final = spark_df_final.toPandas()\n",
        "display(df_pandas_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "M-tU-5s-9GrG",
        "outputId": "6c458a4f-9b64-41ec-eee7-ab0c1c4ec7ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0                          Cyprus Mail News and More   \n",
              "1  Man United spoil West Ham party to reach FA Cu...   \n",
              "2             APOEL face Olympiacos in Europa League   \n",
              "3   Cabinet reappoints Kalogirou as CySEC chairwoman   \n",
              "4  UEFA keeps it in the family as Champions Leagu...   \n",
              "5                       Geeks rule at CyprusComicCon   \n",
              "6  AEK stranded in Czech Republic, fixture postponed   \n",
              "\n",
              "             Predicted_Brand Predicted_Sentiment     positive     neutral  \\\n",
              "0  Cyprus Mail News and More             neutral   0.03859538  0.92489934   \n",
              "1                 Man United             neutral   0.18306758   0.8001094   \n",
              "2                 Olympiacos             neutral  0.054285355   0.9071312   \n",
              "3                      CySEC             neutral  0.045380317   0.9248033   \n",
              "4                       UEFA             neutral  0.037894398   0.9407692   \n",
              "5             CyprusComicCon             neutral  0.022995396   0.9111386   \n",
              "6                        AEK            negative    0.0213757  0.20137864   \n",
              "\n",
              "      negative     score  \n",
              "0  0.036505282  0.002090  \n",
              "1  0.016823035  0.166245  \n",
              "2   0.03858344  0.015702  \n",
              "3  0.029816337  0.015564  \n",
              "4  0.021336425  0.016558  \n",
              "5   0.06586602 -0.042871  \n",
              "6   0.77724564 -0.755870  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fac6244c-77ed-435a-99b6-b4ddf4e225ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Predicted_Brand</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>negative</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cyprus Mail News and More</td>\n",
              "      <td>Cyprus Mail News and More</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.03859538</td>\n",
              "      <td>0.92489934</td>\n",
              "      <td>0.036505282</td>\n",
              "      <td>0.002090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Man United spoil West Ham party to reach FA Cu...</td>\n",
              "      <td>Man United</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.18306758</td>\n",
              "      <td>0.8001094</td>\n",
              "      <td>0.016823035</td>\n",
              "      <td>0.166245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>APOEL face Olympiacos in Europa League</td>\n",
              "      <td>Olympiacos</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.054285355</td>\n",
              "      <td>0.9071312</td>\n",
              "      <td>0.03858344</td>\n",
              "      <td>0.015702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cabinet reappoints Kalogirou as CySEC chairwoman</td>\n",
              "      <td>CySEC</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.045380317</td>\n",
              "      <td>0.9248033</td>\n",
              "      <td>0.029816337</td>\n",
              "      <td>0.015564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UEFA keeps it in the family as Champions Leagu...</td>\n",
              "      <td>UEFA</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.037894398</td>\n",
              "      <td>0.9407692</td>\n",
              "      <td>0.021336425</td>\n",
              "      <td>0.016558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Geeks rule at CyprusComicCon</td>\n",
              "      <td>CyprusComicCon</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.022995396</td>\n",
              "      <td>0.9111386</td>\n",
              "      <td>0.06586602</td>\n",
              "      <td>-0.042871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AEK stranded in Czech Republic, fixture postponed</td>\n",
              "      <td>AEK</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0213757</td>\n",
              "      <td>0.20137864</td>\n",
              "      <td>0.77724564</td>\n",
              "      <td>-0.755870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fac6244c-77ed-435a-99b6-b4ddf4e225ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fac6244c-77ed-435a-99b6-b4ddf4e225ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fac6244c-77ed-435a-99b6-b4ddf4e225ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}