{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/python-package/blob/main/johnsnow/Charlize_SNOW_LABS_PIPELINES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYgZXG4gDt1"
      },
      "source": [
        "# **Class for Sentiment Analysis for News Articles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDySD2IHU9di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1adc004-6122-4751-8806-08e69ff575c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 68 kB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 59.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOW8Mt7VH97",
        "outputId": "89b456a8-6175-4b30-de5c-5ce33fc5f160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.1\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "\n",
        "import sparknlp\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml import Pipeline\n",
        "from tabulate import tabulate\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "\n",
        "spark = sparknlp.start(gpu=False)\n",
        "# spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a News Article"
      ],
      "metadata": {
        "id": "BDijGosdPGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = [ # two strings - headline & article body\n",
        "\"\"\"Google sued in US over 'deceptive' location tracking\"\"\", # headline\n",
        "\"\"\"Google is being sued in the US over accusations it deceived people about how to control location tracking.\n",
        "\n",
        "The legal action refers to a widely reported 2018 revelation turning off one location-tracking setting in its apps was insufficient to fully disable the feature.\n",
        "\n",
        "It accuses Google of using so-called dark patterns, marketing techniques that deliberately confuse.\n",
        "\n",
        "Google said the claims were inaccurate and outdated.\n",
        "\n",
        "'Unfair practices'\n",
        "The legal action was filed in the District of Columbia. Similar ones were also filed in Texas, Indiana and Washington state.\n",
        "\n",
        "It refers to an Associated Press revelation turning off Location History when using Google Maps or Search was insufficient - as a separate setting, Web and App Activity, continued to log location and other personal data.\n",
        "\n",
        "The study, with researchers at Princeton University, found up to two billion Android and Apple devices could be affected.\n",
        "\n",
        "\"Google has relied on, and continues to rely on, deceptive and unfair practices that make it difficult for users to decline location tracking or to evaluate the data collection and processing to which they are purportedly consenting,\" the legal action alleges.\n",
        "\n",
        "'Robust controls'\n",
        "Google told BBC News the case was based \"on inaccurate claims and outdated assertions about our settings\".\n",
        "\n",
        "A representative added: \"We have always built privacy features into our products and provided robust controls for location data.\n",
        "\n",
        "\"We will vigorously defend ourselves and set the record straight.\"\n",
        "\n",
        "Visual misdirection\n",
        "The legal action claims Google's policies contained other \"misleading, ambiguous and incomplete descriptions... but guarantee that consumers will not understand when their location is collected and retained by Google or for what purposes\".\n",
        "\n",
        "It refers to dark patterns, design choices that alter users' decision-making for the designer's benefit - such as, complicated navigation menus, visual misdirection, confusing wording and repeated nudging towards a particular outcome.\n",
        "\n",
        "Data regulators are increasingly focusing on these practices.\n",
        "\n",
        "Google faces a raft of other legal actions in the US, including:\n",
        "\n",
        "In May 2020, Arizona filed a legal action over the same issue\n",
        "In December 2020, multiple US states sued over the price and process of advertising auctions\n",
        "In October 2020, the US Justice Department alleged Google had a monopoly over search and search advertising\"\"\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "kzD5yHCBTfKL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Brand Identification Class"
      ],
      "metadata": {
        "id": "rmq_-RXkbB1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text') # An empty df with column name \"text\"\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def create_ranked_table(self, text): # text could be a pandas dataframe with a column \"text\" or a list of strings or a single string\n",
        "        # Run the pipeline for the text\n",
        "        if isinstance(text, pd.DataFrame): text_df = spark.createDataFrame(text) # If input a pandas dataframe\n",
        "        elif isinstance(text, str): text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index=[0])) # If input a single string\n",
        "        else: text_df = spark.createDataFrame(pd.DataFrame({'text': text})) # If input a list of strings\n",
        "        result = self.pipeline_model.transform(text_df)\n",
        "        \n",
        "        # Create a table with entity names and types\n",
        "        df = result.select(F.explode(F.arrays_zip('document.result', 'ner_chunk.result',\"ner_chunk.metadata\")).alias(\"cols\")).select(\\\n",
        "        F.expr(\"cols['1']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['2'].entity\").alias('result'))\n",
        "        \n",
        "        # Filter only ORGs\n",
        "        df = df.filter(df.result == 'ORG')\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df.groupBy(df.chunk).count().orderBy('count', ascending=False)\n",
        "\n",
        "        return df, ranked_df\n",
        "\n",
        "\n",
        "    def predict_by_headline(self, headline): # headline can be a pandas df, a list of string or a single string\n",
        "        _, ranked_df_hl = self.create_ranked_table(headline)\n",
        "        # ranked_df_hl.show(100, truncate=False)\n",
        "        \n",
        "        # If no ORG identified in headline, return None\n",
        "        if ranked_df_hl.count() == 0:\n",
        "            return None\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif ranked_df_hl.count() == 1:\n",
        "            return ranked_df_hl.first()[0]\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df_hl.first()[1] > ranked_df_hl.collect()[1][1]:\n",
        "            return ranked_df_hl.first()[0] \n",
        "        else: # If multiple ORGs appear the same time, leave decision to article body (TO BE MODIFIED)\n",
        "            return None\n",
        "            # return ranked_df_hl.first()[0] \n",
        "\n",
        "\n",
        "    def predict(self, headline, body): # body can be a pandas df, a list of string or a single string\n",
        "        _, ranked_df = self.create_ranked_table(body)\n",
        "\n",
        "        # Return the ORG with highest freq (at least >= 2)\n",
        "        if ranked_df.first()[1] >= 2: \n",
        "            return ranked_df.first()[0] \n",
        "        else:\n",
        "            return None\n",
        "        # TO DO: break even - Wikidata#"
      ],
      "metadata": {
        "id": "5JQeWnV1a8Fh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Sentiment Identification Class"
      ],
      "metadata": {
        "id": "-5m65UosNdY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "          document_assembler = DocumentAssembler() \\\n",
        "              .setInputCol('text') \\\n",
        "              .setOutputCol('document')\n",
        "\n",
        "          tokenizer = Tokenizer() \\\n",
        "              .setInputCols(['document']) \\\n",
        "              .setOutputCol('token')\n",
        "\n",
        "          sequenceClassifier = BertForSequenceClassification \\\n",
        "                .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                .setInputCols(['token', 'document']) \\\n",
        "                .setOutputCol('class') \\\n",
        "                .setCaseSensitive(True) \\\n",
        "                .setMaxSentenceLength(512)\n",
        "\n",
        "          pipeline = Pipeline(stages=[\n",
        "              document_assembler,\n",
        "              tokenizer,\n",
        "              sequenceClassifier\n",
        "          ])\n",
        "\n",
        "          self.pipeline_model = LightPipeline(pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\")))\n",
        "\n",
        "        else:\n",
        "          self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"Predicts sentiment of the input string..\n",
        "\n",
        "        Args:\n",
        "          text: String to classify.\n",
        "        \"\"\"\n",
        "        self.text = text\n",
        "\n",
        "        # Annotate input text using pretrained model\n",
        "        annotations =  self.pipeline_model.annotate(self.text)\n",
        "\n",
        "        # Depending on the chosen pipeline the outputs will be slightly different\n",
        "        if self.MODEL_NAME == \"analyze_sentimentdl_glove_imdb\":\n",
        "          # print(f\"{annotations['sentiment']} {annotations['document']}\")\n",
        "\n",
        "          if isinstance(self.text, list):\n",
        "            return [annotation['sentiment'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "          else:\n",
        "            return annotations['sentiment'][0] # Return the sentiment string\n",
        "\n",
        "        else:\n",
        "          # print(f\"{annotations['class']} {annotations['document']}\")\n",
        "\n",
        "          if isinstance(self.text, list):\n",
        "            return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "          else:\n",
        "            return annotations['class'][0] # Return the sentiment string"
      ],
      "metadata": {
        "id": "62AefsLpNiTB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Brand in news article\n"
      ],
      "metadata": {
        "id": "MwBY37mRbKjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)\n",
        "headline, body = article\n",
        "\n",
        "brand_by_headline = brand_identifier.predict_by_headline(headline)\n",
        "print(brand_by_headline)\n",
        "\n",
        "# Only use article body if no brand identified in the headline\n",
        "if brand_by_headline == None:\n",
        "    brand = brand_identifier.predict(body)\n",
        "    print(brand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUgFEXqubJwk",
        "outputId": "5461352e-7dad-496d-f6aa-3df92270c093"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n",
            "Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify article using chosen pipeline"
      ],
      "metadata": {
        "id": "HoTrh-sEUeRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifier = SentimentIdentification(MODEL_NAME =  \"analyze_sentimentdl_glove_imdb\")\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # Uses https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "\n",
        "# Predict by headline\n",
        "headline = article[0]\n",
        "identifier.predict(headline)\n",
        "\n",
        "# Predict by body\n",
        "body = article[1]\n",
        "identifier.predict(body)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RMwzvEYnPKEQ",
        "outputId": "ecbf00cb-48b9-4b32-a754-a6b2ab7274ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the accuracy of sentiment using Kaggle data (Financial News Headlines)"
      ],
      "metadata": {
        "id": "5GVcdPcr3Ldk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER "
      ],
      "metadata": {
        "id": "-QvbGQDaOR3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Kaggle data to Pandas dataframe and preprocess"
      ],
      "metadata": {
        "id": "QpKHFStDuQJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from Github\n",
        "NER_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/NER_test_data.csv'\n",
        "\n",
        "# Convert data to Pandas dataframe \n",
        "df_NER = pd.read_csv(NER_url).head(500)\n",
        "df_NER.columns = ['Brand', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "df_NER = df_NER.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 100\n",
        "total_num_sentences = df_NER.shape[0]\n",
        "df_NER.drop(df_NER.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "df_NER"
      ],
      "metadata": {
        "id": "p7fSpePI1K-G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87df4f18-8c81-4358-8437-ea0b37c7bd60"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3605c4e4-0e42-405e-b28a-36f276f354cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>None</td>\n",
              "      <td>Sales of security and system packaging increas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>None</td>\n",
              "      <td>Operating profit surged to EUR21m from EUR106 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>None</td>\n",
              "      <td>Net income from life insurance rose to EUR 16....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Helsinki Stock Exchange</td>\n",
              "      <td>The 718,430 new Series A shares will become su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Bank of +_land</td>\n",
              "      <td>Finnish Bank of +_land 's consolidated net ope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>None</td>\n",
              "      <td>Compared with the FTSE 100 index , which rose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>Baltic Pearl CJSC</td>\n",
              "      <td>The mall is part of the Baltic Pearl developme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>Bunge</td>\n",
              "      <td>Furthermore , Bunge will also sign a licensing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>Orion</td>\n",
              "      <td>Finnish pharmaceuticals company Orion 's net s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>None</td>\n",
              "      <td>In Lithuania , operating profit rose to EUR 19...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3605c4e4-0e42-405e-b28a-36f276f354cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3605c4e4-0e42-405e-b28a-36f276f354cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3605c4e4-0e42-405e-b28a-36f276f354cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       Brand                                               text\n",
              "367                     None  Sales of security and system packaging increas...\n",
              "253                     None  Operating profit surged to EUR21m from EUR106 ...\n",
              "40                      None  Net income from life insurance rose to EUR 16....\n",
              "79   Helsinki Stock Exchange  The 718,430 new Series A shares will become su...\n",
              "93            Bank of +_land  Finnish Bank of +_land 's consolidated net ope...\n",
              "..                       ...                                                ...\n",
              "422                     None  Compared with the FTSE 100 index , which rose ...\n",
              "405        Baltic Pearl CJSC  The mall is part of the Baltic Pearl developme...\n",
              "428                    Bunge  Furthermore , Bunge will also sign a licensing...\n",
              "146                    Orion  Finnish pharmaceuticals company Orion 's net s...\n",
              "106                     None  In Lithuania , operating profit rose to EUR 19...\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the brand in each sentence & compute accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "_NYARSWW3-X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\" / \"ner_dl\"\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGW3Pdx9_4q7",
        "outputId": "26b7f4c4-1061-42df-f26d-ba117c3808a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Measure how long to create a ranked table for one headline (string) only\n",
        "# Randomly select one headline\n",
        "hl_str = df_NER.iloc[8, 1]\n",
        "# print(hl_str)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "df, ranked_df = brand_identifier.create_ranked_table(hl_str)\n",
        "# df.show() \n",
        "# ranked_df.show() # Showing both tables takes 5 seconds\n",
        "\n",
        "mid = time.time()\n",
        "\n",
        "brand = brand_identifier.predict_by_headline(hl_str)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{mid-start} seconds elapsed to create a ranked table for 1 sentence.\")\n",
        "print(f\"{end-mid} seconds elapsed to predict a brand for 1 sentence.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyiTTLWXFw_K",
        "outputId": "be120953-86c1-4fd1-883c-8b567835b9ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.82338547706604 seconds elapsed to create a ranked table for 1 sentence.\n",
            "25.070236921310425 seconds elapsed to predict a brand for 1 sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Measure how long to create a ranked table for a pandas dataframe of 100 headlines\n",
        "start = time.time()\n",
        "\n",
        "df, ranked_df = brand_identifier.create_ranked_table(df_NER) # The pandas df is changed to a spark df\n",
        "# df.show(300, truncate=False) \n",
        "# ranked_df.show(100, truncate=False) # Showing both tables takes 40 seconds\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to create ranked tables for {num_sentences} sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mgGVMmGQuwK",
        "outputId": "a78e600e-b2e4-4748-a231-1a38163bd7e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9220077991485596 seconds elapsed to create ranked tables for 100 sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Measure how long to create a ranked table for the list of 100 headlines\n",
        "# Create a list of headline strings\n",
        "hl_list = df_NER['text'].tolist()\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "df, ranked_df = brand_identifier.create_ranked_table(hl_list) # The list is first changed into a pandas df, then a spark df\n",
        "# df.show(300, truncate=False) \n",
        "# ranked_df.show(100, truncate=False) # Showing both tables takes 40 seconds\n",
        "\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to create a ranked table for {num_sentences} sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqXewWZpDVuO",
        "outputId": "97aec406-8bc3-428a-9c10-18f2ff525e88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8399128913879395 seconds elapsed to create a ranked table for 100 sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Measure how long it takes to create a ranked table for each headline, then identify a brand from the table using a for loop\n",
        "start = time.time()\n",
        "\n",
        "# Use list comprehension to identify a brand for each headline (row)\n",
        "df_NER['Predicted Brand'] = [brand_identifier.predict_by_headline(hl) for hl in df_NER['text']]\n",
        "\n",
        "end = time.time()\n",
        "print(f\"{(end-start)} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Compute the accuracy\n",
        "y_true = df_NER['Brand'].to_numpy()\n",
        "y_pred = df_NER['Predicted Brand'].to_numpy()\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "print(df_NER) # Variation issue in names is rare"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOjUHGMw4DlA",
        "outputId": "39e556d6-b3c1-40ec-d185-3f246e326495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609.7073035240173 seconds elapsed to classify 100 sentences.\n",
            "The accuracy is 22.0%. \n",
            "\n",
            "                                Brand  ...                   Predicted Brand\n",
            "164                              None  ...                              None\n",
            "12                           Talentum  ...                  Finnish Talentum\n",
            "34                         Sanoma Oyj  ...                              None\n",
            "179                              None  ...                               EUR\n",
            "206                              None  ...                              None\n",
            "195                       Outotec Oyj  ...                       Outotec Oyj\n",
            "451                              None  ...                              None\n",
            "60                              Atria  ...                             Atria\n",
            "80                               None  ...                              None\n",
            "408                           Tradeka  ...                           Tradeka\n",
            "411                              None  ...                              None\n",
            "227                       Affecto Oyj  ...                              None\n",
            "291                              None  ...                              None\n",
            "441                          Ramirent  ...                              None\n",
            "69                               None  ...                      OMX Helsinki\n",
            "211  Lithuanian Brewers ' Association  ...  Lithuanian Brewers ' Association\n",
            "332                       Okmetic Oyj  ...                              None\n",
            "250                              None  ...                               EUR\n",
            "385                              None  ...                              None\n",
            "129                              None  ...                              None\n",
            "45             Nokia Siemens Networks  ...            Nokia Siemens Networks\n",
            "200                Done Solutions Oyj  ...                Done Solutions Oyj\n",
            "454                              None  ...                        Talvivaara\n",
            "40                               None  ...                               EUR\n",
            "108                              None  ...                              None\n",
            "48                               None  ...                              None\n",
            "39                            Fiskars  ...                               EUR\n",
            "187                              None  ...                               EPS\n",
            "327                              None  ...                              None\n",
            "498                     Sports Direct  ...                     Sports Direct\n",
            "137                   Rapala VMC Corp  ...                              None\n",
            "70                               None  ...                              None\n",
            "139                    Metso Minerals  ...                              None\n",
            "105                           Fiskars  ...                           Fiskars\n",
            "172                              None  ...                              None\n",
            "483                          Cargotec  ...                              None\n",
            "344                          Vacon Oy  ...                              None\n",
            "196                    Componenta Oyj  ...                    Componenta Oyj\n",
            "94                              Aktia  ...                             Aktia\n",
            "381                              None  ...                              None\n",
            "399                           Pohjola  ...                           Pohjola\n",
            "431                            Raisio  ...                              None\n",
            "450                              None  ...                            Apollo\n",
            "24                            Teleste  ...                              None\n",
            "457                              None  ...                              None\n",
            "207                              None  ...                           Ragutis\n",
            "353                              Olvi  ...                              Olvi\n",
            "125                              None  ...                              None\n",
            "120                          Ramirent  ...                          Ramirent\n",
            "167                              None  ...                              None\n",
            "84                               None  ...                              None\n",
            "148                             Sappi  ...                              None\n",
            "142                             Aktia  ...                             Aktia\n",
            "348                              None  ...                              None\n",
            "146                             Orion  ...                             Orion\n",
            "307                             Vacon  ...                             Vacon\n",
            "438                          Grimaldi  ...                              None\n",
            "475                              None  ...    U.S. Patent & Trademark Office\n",
            "15                 Foundries division  ...                      Machine Shop\n",
            "421                              None  ...                              None\n",
            "419                            Capman  ...                              None\n",
            "497                              None  ...                              None\n",
            "314                           BasWare  ...                           BasWare\n",
            "246                              None  ...                               EUR\n",
            "219                              None  ...                              None\n",
            "123                            Ruukki  ...                            Ruukki\n",
            "73                         Sponda Plc  ...                              None\n",
            "218                              None  ...                              None\n",
            "33                               None  ...                         Kapiteeli\n",
            "358                              None  ...                              None\n",
            "312                              None  ...                              None\n",
            "439                             Nokia  ...                              None\n",
            "415                              None  ...    U.S. Patent & Trademark Office\n",
            "101                         Sepp+Æl+Æ  ...                              None\n",
            "468                              None  ...                              None\n",
            "76                               None  ...                              None\n",
            "369                              None  ...                              None\n",
            "479                        Biohit Oyj  ...                        Biohit Oyj\n",
            "386                              None  ...                              None\n",
            "116                              None  ...                              None\n",
            "251                              None  ...                              None\n",
            "283                              None  ...                              None\n",
            "257                              None  ...                               EUR\n",
            "423                              None  ...                              None\n",
            "374                              None  ...                              None\n",
            "254                              None  ...                               EUR\n",
            "405                 Baltic Pearl CJSC  ...                              None\n",
            "42                               None  ...                              None\n",
            "304                           Comptel  ...                           Comptel\n",
            "188                              None  ...                              None\n",
            "462           Standard Chartered Bank  ...                              None\n",
            "234                              None  ...                               EUR\n",
            "287                              None  ...                              None\n",
            "155                     Lemmink+Æinen  ...                Also Lemmink+Æinen\n",
            "384                              None  ...                              None\n",
            "488                        Konecranes  ...                              None\n",
            "134                             Cramo  ...                             Cramo\n",
            "453                              None  ...                              None\n",
            "198                     Stonesoft Oyj  ...                     Stonesoft Oyj\n",
            "268                              None  ...                              EBIT\n",
            "\n",
            "[100 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify all brands using Spark Dataframe of sentences as input "
      ],
      "metadata": {
        "id": "ehtVDL9_X5lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Try creating spark dataframes in UDF - this doesn't work as no SparkContext should be called inside the function\n",
        "\n",
        "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, MapType, ArrayType\n",
        "\n",
        "# Convert the pandas df to spark df\n",
        "# df_spark_org = spark.createDataFrame(df_NER)  # Only keep the 'text' column\n",
        "# df_spark_org = df_spark_org.limit(10)\n",
        "# df_spark = brand_identifier.pipeline_model.transform(df_spark_org)\n",
        "# df_spark.printSchema()\n",
        "# df_spark.select(\"ner_chunk\").printSchema()\n",
        "\n",
        "# start = time.time()\n",
        "\n",
        "# # Each row of this spark df contains all identified entities for one sentence\n",
        "# df_spark.select(\"ner_chunk\").show(2, truncate=False) \n",
        "# df_spark.select(\"ner_chunk\").first() # pyspark.sql.types.Row\n",
        "\n",
        "# row = df_spark.select(\"ner_chunk\").collect()[1][0]\n",
        "# schema = StructType([StructField(\"annotatorType\", StringType(), True),\n",
        "#                      StructField(\"begin\", IntegerType(), True),\n",
        "#                      StructField(\"end\", IntegerType(), True),\n",
        "#                      StructField(\"result\", StringType(), True), \n",
        "#                      StructField(\"metadata\", MapType(StringType(), StringType()), True),\n",
        "#                      StructField(\"embeddings\", ArrayType(FloatType()), True)])\n",
        "# df = spark.createDataFrame(row, schema = schema)\n",
        "# df = df.select(\n",
        "#     F.col('result').alias('chuck'),\n",
        "#     F.col('metadata.entity').alias('result')\n",
        "# )\n",
        "# df.show()\n",
        "\n",
        "# df.select(F.explode(F.arrays_zip('result',\"metadata\")).alias(\"cols\")).select(\\\n",
        "#             F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "#             F.expr(\"cols['1'].entity\").alias('result'))\n",
        "# rdd = spark.sparkContext.parallelize(row)\n",
        "# df = rdd.toDF()\n",
        "# df.show()\n",
        "\n",
        "# row = df_spark.select(\"ner_chunk\").first()[0][0]\n",
        "# row.result\n",
        "# row.metadata['entity']\n",
        "\n",
        "# pred_brand = udf(lambda z: get_brand(z), StringType()) # Default output is string\n",
        "# spark.udf.register(\"pred_brand\", pred_brand)\n",
        "# def get_brand(row):\n",
        "#     if not row: # If the list is empty, i.e. no ORG identified in headline\n",
        "#         return None \n",
        "\n",
        "#     else:\n",
        "#         # Create a table with entity names and types\n",
        "#         schema = StructType([StructField(\"annotatorType\", StringType(), True),\n",
        "#                  StructField(\"begin\", IntegerType(), True),\n",
        "#                  StructField(\"end\", IntegerType(), True),\n",
        "#                  StructField(\"result\", StringType(), True), \n",
        "#                  StructField(\"metadata\", MapType(StringType(), StringType()), True),\n",
        "#                  StructField(\"embeddings\", ArrayType(FloatType()), True)])\n",
        "#         df = spark.createDataFrame(row, schema = schema)\n",
        "#         df = df.select(F.col('result').alias('chuck'),\n",
        "#                        F.col('metadata.entity').alias('result'))\n",
        "  \n",
        "#         # Filter only ORGs\n",
        "#         df = df.filter(df.result == 'ORG')\n",
        "\n",
        "#         # Rank the ORGs by frequencies\n",
        "#         ranked_df = df.groupBy(df.chunk).count().orderBy('count', ascending=False)\n",
        "        \n",
        "#         # # If no ORG identified in headline, return None\n",
        "#         # if ranked_df.count() == 0:\n",
        "#         #     return None\n",
        "#         # If only one ORG appears in headline, return it\n",
        "#         if ranked_df.count() == 1:\n",
        "#             return ranked_df.first()[0]\n",
        "#         # If one ORG appear more than the others, return that one \n",
        "#         elif ranked_df.first()[1] > ranked_df.collect()[1][1]:\n",
        "#             return ranked_df.first()[0] \n",
        "#         else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "#             return ranked_df.first()[0] \n",
        "\n",
        "# df_spark_combined = df_spark.withColumn('Predicted Brand', pred_brand(\"ner_chunk\"))\n",
        "# df_spark_combined.show(5)\n",
        "\n",
        "# end = time.time()\n",
        "\n",
        "# print(f\"{end-start} seconds elapsed to create ranked tables for {num_sentences} sentences.\")"
      ],
      "metadata": {
        "id": "Yi1cjTqN2Yz-",
        "outputId": "bb8317fe-1d2a-47a6-bc54-a12b835b8f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(brand='Elcoteq')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve speed of identification using Spark User-defined function\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "df_spark_org = spark.createDataFrame(df_NER)  # Only keep the 'text' column\n",
        "# df_spark_org = df_spark_org.limit(10)\n",
        "df_spark = brand_identifier.pipeline_model.transform(df_spark_org)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pred_brand = udf(lambda z: get_brand(z), StringType()) # Output a string\n",
        "# spark.udf.register(\"pred_brand\", pred_brand)\n",
        "def get_brand(row_list):\n",
        "    if not row_list: # If the list is empty\n",
        "        return \"None\"\n",
        "\n",
        "    else:\n",
        "        # Create a pandas df with entity names and types\n",
        "        data = [[row.result, row.metadata['entity']] for row in row_list]\n",
        "        df_pd = pd.DataFrame(data, columns = ['Entity', 'Type'])\n",
        "  \n",
        "        # Filter only ORGs\n",
        "        df_pd = df_pd[df_pd[\"Type\"] == \"ORG\"]\n",
        "\n",
        "        # Rank the ORGs by frequencies\n",
        "        ranked_df = df_pd[\"Entity\"].value_counts() # a Pandas Series object\n",
        "        \n",
        "        # If no ORG identified in headline, return None\n",
        "        if len(ranked_df.index) == 0:\n",
        "           return \"None\"\n",
        "\n",
        "        # If only one ORG appears in headline, return it\n",
        "        elif len(ranked_df.index) == 1:\n",
        "           return ranked_df.index[0]\n",
        "\n",
        "        # If one ORG appear more than the others, return that one \n",
        "        elif ranked_df[0] > ranked_df[1]:\n",
        "            return ranked_df.index[0] \n",
        "\n",
        "        else: # If multiple ORGs appear the same time, return randomly (TO BE MODIFIED)\n",
        "            return random.choice([ranked_df.index[0], ranked_df.index[1]])\n",
        "\n",
        "# pred_brand_col = pred_brand(df_spark.ner_chunk)\n",
        "df_spark_combined = df_spark.withColumn('Predicted Brand', pred_brand('ner_chunk'))\n",
        "df_spark_final = df_spark_combined.select(\"Brand\", \"Predicted Brand\")\n",
        "df_spark_final.show(100)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to create ranked tables for {num_sentences} sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9smD7qJWX5X",
        "outputId": "9bdf8924-f815-444b-8be5-7ecad8ef0013"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|               Brand|     Predicted Brand|\n",
            "+--------------------+--------------------+\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|                None|                 EUR|\n",
            "|Helsinki Stock Ex...|           Main List|\n",
            "|      Bank of +_land|Finnish Bank of +...|\n",
            "|             Teleste|              Satlan|\n",
            "|                None|              EUR179|\n",
            "|                None|              Pretax|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|         Viking Line|         Viking Line|\n",
            "|               Tekla|               Tekla|\n",
            "|         TeliaSonera|         TeliaSonera|\n",
            "|                None|                None|\n",
            "|              Ruukki|                None|\n",
            "|       Biohit , Inc.|        Biohit , Inc|\n",
            "|             Comptel|             Comptel|\n",
            "|                None|                None|\n",
            "|Standard Chartere...|    BEIJING XFN-ASIA|\n",
            "|    ESL Shipping Ltd|    ESL Shipping Ltd|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|               Nokia|                None|\n",
            "|                Kone|                Kone|\n",
            "|              Sponda|       SPONDA Sponda|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|      Grimaldi Group|      Grimaldi Group|\n",
            "|                 SEB|                SEK1|\n",
            "|                None|                None|\n",
            "|                None|                 EPS|\n",
            "|                None|                 EUR|\n",
            "|                None|U.S. Patent & Tra...|\n",
            "|               Digia|               Digia|\n",
            "|           Tecnotree|           Tecnotree|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|           Finnlines|           Finnlines|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|       Stonesoft Oyj|       Stonesoft Oyj|\n",
            "|        Marimekko Oy|                 HEL|\n",
            "|                None|                None|\n",
            "|               Nokia|               Nokia|\n",
            "|      KCI Konecranes|                None|\n",
            "|      GeoSentric Oyj|      GeoSentric Oyj|\n",
            "|     Rapala VMC Corp|                 HEL|\n",
            "|                None|                None|\n",
            "|          Konecranes|          Konecranes|\n",
            "|                 YIT|                 YIT|\n",
            "|          Alma Media|          Alma Media|\n",
            "|                None|Department Store ...|\n",
            "|         Vaisala Oyj|            ADP News|\n",
            "|Credit Suisse Fir...|         NORSKE SKOG|\n",
            "|       Outokumpu Oyj|   Outokumpu Oyj HEL|\n",
            "|               Tekla|    Tekla Structures|\n",
            "|               Sappi|Finnish M-real Co...|\n",
            "|                None|                None|\n",
            "|                None|                 EUR|\n",
            "|                None|U.S. Patent & Tra...|\n",
            "|             Pohjola|             Pohjola|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|            Aspocomp|            Aspocomp|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|                None|                None|\n",
            "|            Cargotec|                None|\n",
            "|            Talentum|    Finnish Talentum|\n",
            "|         Outotec Oyj|         Outotec Oyj|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|          Raisio Oyj|               RAIVV|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|       Sports Direct|       Sports Direct|\n",
            "|             Tiimari|             Tiimari|\n",
            "|           Aspo Plc.|           Aspo Plc.|\n",
            "|              Raisio|       Food Division|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|        Nokian Tyres|        Nokian Tyres|\n",
            "|                None|                None|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|                None|                 EUR|\n",
            "|                None|                None|\n",
            "|           Sepp+Æl+Æ|                 EUR|\n",
            "|                None|                None|\n",
            "|   Baltic Pearl CJSC|        Baltic Pearl|\n",
            "|               Bunge|           Sunnuntai|\n",
            "|               Orion|               Orion|\n",
            "|                None|                 EUR|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "23.367811918258667 seconds elapsed to create ranked tables for 100 sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the accuracy\n",
        "df_pd_post = df_spark_final.toPandas()\n",
        "\n",
        "y_true = df_pd_post['Brand'].to_numpy()\n",
        "y_pred = df_pd_post['Predicted Brand'].to_numpy()\n",
        "print(f\"The accuracy is {100*sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBnLS_2bzRZ4",
        "outputId": "a1ac3323-12a8-49aa-8298-259219c23b57"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 61.0%. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment"
      ],
      "metadata": {
        "id": "LA3mYD2kK2V6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Kaggle data to Pandas dataframe and preprocess"
      ],
      "metadata": {
        "id": "OGdheuC8uMiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_url = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/sentiment_test_data.csv'\n",
        "\n",
        "# Store data in a Pandas Dataframe\n",
        "df_pandas = pd.read_csv(sentiment_url)\n",
        "\n",
        "# Change column names (pipelines require a \"text\" column to predict)\n",
        "df_pandas.columns = ['True_Sentiment', 'text']\n",
        "\n",
        "# Shuffle the DataFrame rows\n",
        "df_pandas = df_pandas.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 100\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "print(df_pandas.shape)\n"
      ],
      "metadata": {
        "id": "nwLHDZohOPJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b910475b-4eb2-4c2a-a4a2-8ca5e6f1c65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the sentiment in each sentence"
      ],
      "metadata": {
        "id": "0jQZPrKIOP3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the identifier object\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # 90.2% accuracy on 500 sentences 89.8% on 1000 sentences\n",
        "identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "\n",
        "preds = []\n",
        "target = []\n",
        "ignored_idxs = []\n",
        "sentiment_to_ignore = \"\" # e.g. neutral\n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Collect predicted sentiment for each headline - take three minutes to run\n",
        "for idx, hl in enumerate(df_pandas['text']):\n",
        "\n",
        "    # Only append the sentiment if it is not the sentiment to ignore (e.g. neutral)\n",
        "    target_sentiment = df_pandas[\"True_Sentiment\"][df_pandas.index[idx]]\n",
        "\n",
        "    if target_sentiment != sentiment_to_ignore:\n",
        "      preds.append(identifier.predict(hl))\n",
        "    else:\n",
        "      ignored_idxs.append(idx)\n",
        "\n",
        "    # Print progress\n",
        "    if idx % 25 == 0:\n",
        "      print(f\"Classification {100*idx/num_sentences}% done.\")\n",
        "\n",
        "# Remove all ignored entries from dataset\n",
        "df_pandas.drop(df_pandas.index[ignored_idxs], inplace=True)\n",
        "\n",
        "df_pandas['Predicted_Sentiment'] = preds\n",
        "\n",
        "# Measure how long it takes\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Modify predicted labels to match with true labels\n",
        "# df = df.replace({'Predicted Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "df_pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "5jFhoWw54zMo",
        "outputId": "f12bd1e4-d316-421f-df10-5b0106514f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "Classification 0.0% done.\n",
            "Classification 25.0% done.\n",
            "Classification 50.0% done.\n",
            "Classification 75.0% done.\n",
            "33.950716972351074 seconds elapsed to classify 100 sentences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d6be4f4f-b512-454e-b43a-e647d8c5a05f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3667</th>\n",
              "      <td>neutral</td>\n",
              "      <td>ADP News - Jan 13 , 2009 - Finnish industrial ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>positive</td>\n",
              "      <td>Elcoteq 's stock of orders has stabilised in t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>neutral</td>\n",
              "      <td>As a result of the merger , the largest profes...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>neutral</td>\n",
              "      <td>AffectoGenimap builds highly customised IT sol...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3903</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The solution is demonstrated on a tablet devel...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>positive</td>\n",
              "      <td>The cooperation will double The Switch 's conv...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3439</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Union and company officials did not return cal...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>positive</td>\n",
              "      <td>Via the Satlan acquisition , Teleste plans to ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>positive</td>\n",
              "      <td>Profitability ( EBIT % ) was 13.9 % , compared...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Rautakesko 's business operations in Norway an...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6be4f4f-b512-454e-b43a-e647d8c5a05f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6be4f4f-b512-454e-b43a-e647d8c5a05f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6be4f4f-b512-454e-b43a-e647d8c5a05f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     True_Sentiment  ... Predicted_Sentiment\n",
              "3667        neutral  ...             neutral\n",
              "2009       positive  ...            positive\n",
              "1177        neutral  ...             neutral\n",
              "2771        neutral  ...             neutral\n",
              "3903        neutral  ...             neutral\n",
              "...             ...  ...                 ...\n",
              "595        positive  ...            positive\n",
              "3439        neutral  ...             neutral\n",
              "310        positive  ...            positive\n",
              "875        positive  ...            positive\n",
              "539         neutral  ...            positive\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure the Accuracy"
      ],
      "metadata": {
        "id": "OugF9Z-6t0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = df_pandas['True_Sentiment'].to_numpy()\n",
        "y_pred = df_pandas['Predicted_Sentiment'].to_numpy()\n",
        "\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "\n",
        "# Compute classification metrics - poor accuracy\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiLV0Glo_Kzj",
        "outputId": "d4a850e6-af03-4d40-a099-177b6e8ba2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 90.0%. \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       1.00      0.93      0.97        15\n",
            "     neutral       0.90      0.92      0.91        50\n",
            "    negative       0.86      0.86      0.86        35\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.92      0.90      0.91       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Spark Dataframe as input"
      ],
      "metadata": {
        "id": "PJc83LMsgJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "\n",
        "# Define pretrained pipeline\n",
        "pipeline = PretrainedPipeline(\"classifierdl_bertwiki_finance_sentiment_pipeline\", lang = 'en')\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\")\n",
        "\n",
        "# Convert to spark dataframe for faster prediction\n",
        "df_spark = spark.createDataFrame(df_pandas) \n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Predict the sentiment\n",
        "df_spark = pipeline.transform(df_spark)\n",
        "\n",
        "# # df_spark = identifier.pipeline_model.transform(df_spark)\n",
        "\n",
        "\n",
        "# print(df_spark.first()['class'])\n",
        "# df_spark.printSchema()\n",
        "\n",
        "#Extract sentiment score\n",
        "df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                    col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                    col(\"metadata\")[\"negative\"].alias(\"negative\"))\n",
        "\n",
        "# df_spark_scores = df_spark_scores.withColumn('max_val', greatest('positive', 'negative', 'neutral')) # Doesn't work because of scientific notation\n",
        "\n",
        "# Extract only targets and labels\n",
        "df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "\n",
        "# # df_spark_no_text = df_spark.select(\"True_Sentiment\", \"result\")\n",
        "# # df_spark_no_text = df_spark_no_text.withColumn(\"Predicted_Sentiment\", array_join(\"result\", \"\"))\n",
        "\n",
        "# Rename to Predicted Sentiment\n",
        "df_spark = df_spark.withColumnRenamed(\"result\",\"Predicted_Sentiment\")\n",
        "\n",
        "# Convert sentiment from a list to a string\n",
        "df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "# Merge the predictions and the confidence scores\n",
        "\n",
        "# Add temporary column index to join\n",
        "w = Window.orderBy(monotonically_increasing_id())\n",
        "df_spark_with_index =  df_spark.withColumn(\"columnindex\", row_number().over(w))\n",
        "df_spark_scores_with_index =  df_spark_scores.withColumn(\"columnindex\", row_number().over(w))\n",
        "\n",
        "# Join the predictions and the scores in one dataframe\n",
        "df_spark_with_index = df_spark_with_index.join(df_spark_scores_with_index,\n",
        "                         df_spark_with_index.columnindex == df_spark_scores_with_index.columnindex,\n",
        "                         'inner').drop(df_spark_scores_with_index.columnindex)\n",
        "\n",
        "# Remove the index column\n",
        "df_spark_combined = df_spark_with_index.drop(df_spark_with_index.columnindex)\n",
        "\n",
        "# Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "df_pandas_postprocessed = df_spark_combined.toPandas()\n",
        "# df_pandas_postprocessed = df_spark.toPandas()\n",
        "\n",
        "# df_pandas[\"Predicted_Sentiment\"] = df_pandas[\"Predicted_Sentiment\"].apply(lambda x: x[0]) # Alternative to convert list to string\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# df_pandas_post_processed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plG0dY_MZu5Z",
        "outputId": "0a152cfa-6bc3-4b8c-f047-3f30e62f001e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n",
            "26.504663228988647 seconds elapsed to classify 100 sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the Accuracy"
      ],
      "metadata": {
        "id": "jsCyAYiYOutA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Compute the accuracy\n",
        "accuracy = accuracy_score(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"])\n",
        "print(f\"The accuracy is {accuracy*100}%.\")\n",
        "print(classification_report(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"]))\n",
        "\n",
        "# Alternatively if not converted to pandas dataframe, use the following for the accuracy\n",
        "# Compute accuracy by comparing each true label with predicted label\n",
        "start = time.time()\n",
        "accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to calculate accuracy of {num_sentences} sentences.\")\n",
        "print(f\"The accuracy is {accuracy*100}%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZsstjzhOtko",
        "outputId": "640c8de5-2bfa-4186-a89d-5c97415047c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 90.0%.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.93      0.97        15\n",
            "     neutral       0.90      0.92      0.91        50\n",
            "    positive       0.86      0.86      0.86        35\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.92      0.90      0.91       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n",
            "28.48450493812561 seconds elapsed to calculate accuracy of 100 sentences.\n",
            "The accuracy is 90.0%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternatively extract predictions as strings (takes much longer)"
      ],
      "metadata": {
        "id": "bgCjIm4CK8mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract the predictions from the dataframe\n",
        "# annotations_list = result.select(\"class.result\").collect()\n",
        "# sentiment_list = [annotations_list[i].result[0] for i in range(num_sentences)]\n",
        "\n",
        "# # Annotate previous dataframe for visualization\n",
        "# df_pandas['Predicted Sentiment'] = sentiment_list\n",
        "\n",
        "# # Move text column to the beginning\n",
        "# text_column = df_pandas.pop('text')\n",
        "# df_pandas.insert(0, 'Headline', text_column)\n",
        "\n",
        "# display(df_pandas)\n",
        "\n",
        "# y_true = df_pandas['True Sentiment'].to_numpy()\n",
        "# y_pred = df_pandas['Predicted Sentiment'].to_numpy()\n",
        "\n",
        "# print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "id": "FE7qhsf8LAre"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BDijGosdPGzW",
        "rmq_-RXkbB1d",
        "-5m65UosNdY5",
        "MwBY37mRbKjm",
        "HoTrh-sEUeRf",
        "QpKHFStDuQJ-",
        "OugF9Z-6t0PT"
      ],
      "name": "Charlize - CLASS FOR SENTIMENT DETECTION USING SNOW LABS PIPELINES.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}