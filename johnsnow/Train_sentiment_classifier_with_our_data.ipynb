{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brand-Sentiment-Tracking/dev-sentiment-package/blob/main/johnsnow/Train_sentiment_classifier_with_our_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph3bDypIEXdd"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVmDt1TEXdh"
      },
      "source": [
        "# Spark NLP\n",
        "### Multi-class Sentiment Classification\n",
        "#### By using SentimentDL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmo3o-b3MF5W"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/SentimentDL_train_multiclass_sentiment_classifier.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4fQwZ46x4fu"
      },
      "source": [
        "Only run this block if you are inside Google Colab otherwise skip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzishpT-MF5X",
        "outputId": "a04160d3-484a-414f-9934-02ee7620d7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-26 15:21:38--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-04-26 15:21:38--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-04-26 15:21:39--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1453 (1.4K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.4.3\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.4.3\n",
            "-                   100%[===================>]   1.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-26 15:21:39 (32.7 MB/s) - written to stdout [1453/1453]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmvv5Q4jMF5b",
        "outputId": "146ad886-0efc-469a-ebac-e784af2b1341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.3\n",
            "Apache Spark version 3.0.3\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load political dataset"
      ],
      "metadata": {
        "id": "YFP74juaxxZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Kaggle data to Pandas dataframe and preprocess\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import rand \n",
        "\n",
        "sentiment_url_1 = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/sentiment_test_data.csv' # Financial Phrase Bank\n",
        "sentiment_url_2 = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/python-package/main/data/SEN_en_R.csv' # SEN data\n",
        "sentiment_url_3 = 'https://raw.githubusercontent.com/Brand-Sentiment-Tracking/dev-sentiment-package/main/data/labelled_1.csv' # owr extracted data\n",
        "\n",
        "\n",
        "\n",
        "# # Create a preprocessed spark dataframe\n",
        "# from pyspark import SparkFiles\n",
        "# spark.sparkContext.addFile(sentiment_url_3)\n",
        "\n",
        "# # Read financial dataframe\n",
        "# df_spark = spark.read.option(\"header\",\"false\").csv(\"file://\"+SparkFiles.get(\"sentiment_test_data.csv\"))\n",
        "# df_spark = df_spark.withColumnRenamed(\"_c0\", \"label\").withColumnRenamed(\"_c1\", \"text\")\n",
        "# # Shuffle dataset\n",
        "# df_spark = df_spark.orderBy(rand(2))\n",
        "\n",
        "# # Read political dataframe\n",
        "# df_spark = spark.read.option(\"header\",\"true\").csv(\"file://\"+SparkFiles.get(\"SEN_en_R.csv\"))\n",
        "# df_spark = df_spark.withColumnRenamed(\"_c0\", \"idx\").withColumnRenamed(\"headline\", \"text\") \\\n",
        "#                                                  .withColumnRenamed(\"majority_label\", 'label')\n",
        "# # Replace abbreviations with full lables and filter the unk datapoints (applies only to political dataset)                                         \n",
        "# df_spark = df_spark.replace(\"neutr\", \"neutral\").replace(\"pos\", \"positive\").replace(\"neg\",\"negative\")\n",
        "# df_spark = df_spark[df_spark.label != \"unk\"]\n",
        "\n",
        "# # Read our own dataframe\n",
        "\n",
        "cols_to_read = ['text',\"sentiment (Max's take)\"]\n",
        "df_pandas = pd.read_csv(sentiment_url_3, usecols=cols_to_read)\n",
        "\n",
        "# Rename sentiment to True_Sentiment\n",
        "df_pandas.rename(columns={\"sentiment (Max's take)\":\"True_Sentiment\"},inplace=True)\n",
        "\n",
        "# # Make dataset smaller for faster runtime\n",
        "num_sentences = 500\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)\n",
        "\n",
        "# Replace 1, 2 , 3 with negative, neutral, positive\n",
        "df_pandas[\"True_Sentiment\"].replace({1.0: \"negative\", 2.0: \"neutral\", 3.0: \"positive\"}, inplace=True)\n",
        "\n",
        "# Downsample majority class neutral\n",
        "negative_points = df_pandas[df_pandas[\"True_Sentiment\"] == 'negative'].head(50)\n",
        "neutral_points = df_pandas[df_pandas[\"True_Sentiment\"] == 'neutral'].head(100)\n",
        "positive_points = df_pandas[df_pandas[\"True_Sentiment\"] == 'positive'].head(50)\n",
        "\n",
        "print(len(neutral_points))\n",
        "print(len(positive_points))\n",
        "print(len(negative_points))\n",
        "\n",
        "# Downsample negative class\n",
        "\n",
        "# Concatenate\n",
        "df_pandas = pd.concat([negative_points, neutral_points, positive_points])\n",
        "\n",
        "# Shuffle\n",
        "df_pandas = df_pandas.sample(frac=1)\n",
        "\n",
        "# # Convert to spark dataframe  \n",
        "df_spark = spark.createDataFrame(df_pandas)\n",
        "\n",
        "df_spark.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvV3IUsgx0Ys",
        "outputId": "46c0d8c8-f325-41fa-ed07-39306750a4f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "50\n",
            "50\n",
            "+--------------------+--------------+\n",
            "|                text|True_Sentiment|\n",
            "+--------------------+--------------+\n",
            "|Slovak former pre...|      negative|\n",
            "|Liberty Latin Ame...|      positive|\n",
            "|After-school ‘Sat...|       neutral|\n",
            "|CPI figures highl...|       neutral|\n",
            "|Veeva Vault CTMS ...|      positive|\n",
            "|Shock as Linda No...|      negative|\n",
            "|Putin Calls off P...|       neutral|\n",
            "|BGBS 2022 saw hig...|      positive|\n",
            "|Investigation lau...|       neutral|\n",
            "|Remembering Bedfo...|       neutral|\n",
            "|CA WFO LOS ANGELE...|       neutral|\n",
            "|Phoenix New Media...|      negative|\n",
            "|Hong Kong reopens...|      positive|\n",
            "|‘Corpse After Cor...|      negative|\n",
            "|What makes Alabam...|      positive|\n",
            "|Israeli settlers ...|       neutral|\n",
            "|United Airlines l...|       neutral|\n",
            "|Ambulance crews c...|      negative|\n",
            "|Welltower to Part...|       neutral|\n",
            "|Insteel Industrie...|       neutral|\n",
            "+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test\n",
        "df_spark_train = df_spark.limit(round(df_spark.count()*0.8))\n",
        "df_spark_test = df_spark.subtract(df_spark_train)\n",
        "\n",
        "df_spark_train.show()"
      ],
      "metadata": {
        "id": "b4f9NPIwIMgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ba1b74-6e33-488f-a9dc-66e51bd03506"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+\n",
            "|                text|True_Sentiment|\n",
            "+--------------------+--------------+\n",
            "|Slovak former pre...|      negative|\n",
            "|Liberty Latin Ame...|      positive|\n",
            "|After-school ‘Sat...|       neutral|\n",
            "|CPI figures highl...|       neutral|\n",
            "|Veeva Vault CTMS ...|      positive|\n",
            "|Shock as Linda No...|      negative|\n",
            "|Putin Calls off P...|       neutral|\n",
            "|BGBS 2022 saw hig...|      positive|\n",
            "|Investigation lau...|       neutral|\n",
            "|Remembering Bedfo...|       neutral|\n",
            "|CA WFO LOS ANGELE...|       neutral|\n",
            "|Phoenix New Media...|      negative|\n",
            "|Hong Kong reopens...|      positive|\n",
            "|‘Corpse After Cor...|      negative|\n",
            "|What makes Alabam...|      positive|\n",
            "|Israeli settlers ...|       neutral|\n",
            "|United Airlines l...|       neutral|\n",
            "|Ambulance crews c...|      negative|\n",
            "|Welltower to Part...|       neutral|\n",
            "|Insteel Industrie...|       neutral|\n",
            "+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWFUDI6jMF5k"
      },
      "source": [
        "The content is inside `text` column and the sentiment is inside `label` column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nURzgFJ7MF5o",
        "outputId": "3187919c-633b-4cd7-b133-c905e8c26bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+\n",
            "|                text|True_Sentiment|\n",
            "+--------------------+--------------+\n",
            "|Slovak former pre...|      negative|\n",
            "|Liberty Latin Ame...|      positive|\n",
            "|After-school ‘Sat...|       neutral|\n",
            "|CPI figures highl...|       neutral|\n",
            "|Veeva Vault CTMS ...|      positive|\n",
            "|Shock as Linda No...|      negative|\n",
            "|Putin Calls off P...|       neutral|\n",
            "|BGBS 2022 saw hig...|      positive|\n",
            "|Investigation lau...|       neutral|\n",
            "|Remembering Bedfo...|       neutral|\n",
            "|CA WFO LOS ANGELE...|       neutral|\n",
            "|Phoenix New Media...|      negative|\n",
            "|Hong Kong reopens...|      positive|\n",
            "|‘Corpse After Cor...|      negative|\n",
            "|What makes Alabam...|      positive|\n",
            "|Israeli settlers ...|       neutral|\n",
            "|United Airlines l...|       neutral|\n",
            "|Ambulance crews c...|      negative|\n",
            "|Welltower to Part...|       neutral|\n",
            "|Insteel Industrie...|       neutral|\n",
            "+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainDataset = df_spark_train\n",
        "trainDataset.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NIHJuVKx4gk",
        "outputId": "6034c2d5-edeb-4b8a-cbdc-ec4beccb2b36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "trainDataset.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0oKvNZaEMF5q"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative architecture\n",
        "\n",
        "document = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "bert_cmlm = BertSentenceEmbeddings.pretrained('sent_bert_use_cmlm_en_base', 'en')\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"True_Sentiment\")\\\n",
        "      .setMaxEpochs(10)\\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setLr(0.005)\\\n",
        "      .setBatchSize(20)\n",
        "\n",
        "bert_cmlm_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        bert_cmlm,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1_UCdPXyQAS",
        "outputId": "04f87b22-7cb0-4252-a3c2-36b4393183e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_bert_use_cmlm_en_base download started this may take some time.\n",
            "Approximate size to download 391.6 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "H30A4FgNMF5t"
      },
      "outputs": [],
      "source": [
        "# # actual content is inside description column\n",
        "# document = DocumentAssembler()\\\n",
        "#     .setInputCol(\"text\")\\\n",
        "#     .setOutputCol(\"document\")\n",
        "\n",
        "# use = UniversalSentenceEncoder.pretrained() \\\n",
        "#  .setInputCols([\"document\"])\\\n",
        "#  .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "\n",
        "# classsifierdl = ClassifierDLApproach()\\\n",
        "#   .setInputCols([\"sentence_embeddings\"])\\\n",
        "#   .setOutputCol(\"class\")\\\n",
        "#   .setLabelColumn(\"True_Sentiment\")\\\n",
        "#   .setMaxEpochs(5)\\\n",
        "#   .setEnableOutputLogs(True)\n",
        "\n",
        "# pipeline = Pipeline(\n",
        "#     stages = [\n",
        "#         document,\n",
        "#         use,\n",
        "#         classsifierdl\n",
        "#     ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kia7NpRJMF5v"
      },
      "outputs": [],
      "source": [
        "# Fit to the training dataset (train the model)\n",
        "pipelineModel = bert_cmlm_clf_pipeline.fit(trainDataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMLuwQSCB05e"
      },
      "source": [
        "# How to use already trained SentimentDL pipeline or its model\n",
        "\n",
        "We have two ways of using what we already trained: pipeline or model.\n",
        "\n",
        "Let's see how we can save the entire pipeline, load it, and do some prediction with that pre-trained pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I7COUCPCPe3"
      },
      "source": [
        "## Save and load pre-trained SentimentDL pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QTDQ3riLD-zW"
      },
      "outputs": [],
      "source": [
        "# Google Colab is free so it comes with a little memory. \n",
        "# It's not possible to save and load in this notebook. But you can do this locally or in a decent machine!\n",
        "\n",
        "# pipelineModel.save(\"./sentimentdl_pipeline\")\n",
        "# loadedPipeline = PipelineModel.load(\"./sentimentdl_pipeline\")\n",
        "# loadedPipeline.transform(YOUR_DATAFRAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI9JR8AoLbW3"
      },
      "source": [
        "# Save and load pre-trained SentimentDL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3r3_q4CJLkZR"
      },
      "outputs": [],
      "source": [
        "# hdfs:/ if you are saving it on distributed file systems in Hadoop\n",
        "pipelineModel.stages[-1].write().overwrite().save('./tmp_sentimentdl_model')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JaclNFsQJ-X"
      },
      "source": [
        "Let's use our pre-trained SentimentDLModel in a pipeline: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative architecture\n",
        "\n",
        "document = DocumentAssembler()\\\n",
        "      .setInputCol(\"description\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "bert_cmlm = BertSentenceEmbeddings.pretrained('sent_bert_use_cmlm_en_base', 'en')\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classifierdl = ClassifierDLModel.load(\"./tmp_sentimentdl_model\") \\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\n",
        "\n",
        "bert_cmlm_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        bert_cmlm,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZzX9wJczGbm",
        "outputId": "e2c80f16-fb39-4da0-ce70-fee060e4d015"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_bert_use_cmlm_en_base download started this may take some time.\n",
            "Approximate size to download 391.6 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NTJ53PbYQI-f"
      },
      "outputs": [],
      "source": [
        "# # In a new pipeline you can load it for prediction\n",
        "# document = DocumentAssembler()\\\n",
        "#     .setInputCol(\"text\")\\\n",
        "#     .setOutputCol(\"document\")\n",
        "\n",
        "# use = UniversalSentenceEncoder.pretrained() \\\n",
        "#  .setInputCols([\"document\"])\\\n",
        "#  .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# classifierdl = ClassifierDLModel.load(\"./tmp_sentimentdl_model\") \\\n",
        "#   .setInputCols([\"sentence_embeddings\"])\\\n",
        "#   .setOutputCol(\"class\")\n",
        "\n",
        "# pipeline = Pipeline(\n",
        "#     stages = [\n",
        "#         document,\n",
        "#         use,\n",
        "#         classifierdl\n",
        "#     ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoJH3kA7RJpD"
      },
      "source": [
        "# Evaluation \n",
        "\n",
        "Let's evaluatte our SentimentDL model we trained earlier, saved it, and loaded it into a new pipeline by using a test dataset that model has never seen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_aVPZXgst0-V"
      },
      "outputs": [],
      "source": [
        "testDataset = df_spark_test\n",
        "preds = pipelineModel.transform(testDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H9UAWO_t-b9",
        "outputId": "1353d2c1-b168-44db-8034-4b3ac24d43e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------------------------------------+----------+\n",
            "|True_Sentiment|                                              text|    result|\n",
            "+--------------+--------------------------------------------------+----------+\n",
            "|      negative|Redistricting causing confusion for voters in G...|[positive]|\n",
            "|      negative|Midday Report: Whole Earth Brands (FREE) Trades...|[negative]|\n",
            "|      positive|Report: Transfer Boost For Liverpool And Boruss...|[positive]|\n",
            "|       neutral|Tennessee governor declines to intervene as exe...|[negative]|\n",
            "|       neutral|Serena Williams, Lewis Hamilton Join U.K. Bid T...|[positive]|\n",
            "|       neutral|Lindy Blanchard touts financial independence as...| [neutral]|\n",
            "|       neutral|Pakistan’s new Cabinet sworn in at presidency i...| [neutral]|\n",
            "|       neutral|Man United hires Erik ten Hag as 5th manager in...|[positive]|\n",
            "|      positive|Alberta Investment Management Corporation Annou...|[positive]|\n",
            "|      positive|Local favorites Savannah Seafood Shack, Zunzi's...|[positive]|\n",
            "|      positive|Salt & Straw Brings a Sweet Treat to Disney Spr...|[positive]|\n",
            "|      positive|Transcenta Successfully Passed the Audit of EU ...|[positive]|\n",
            "|      negative|Price Alert: Shares of Acelrx (ACRX) Trade 3.51...|[negative]|\n",
            "|      negative|‘I hope nobody buys this bullsh-t’ - Nate Diaz ...|[positive]|\n",
            "|      negative|German intel: Known antisemitism cases ‘tip of ...| [neutral]|\n",
            "|       neutral|SageView Closes $900 Million Capital One Invest...| [neutral]|\n",
            "|      negative|US officials heading to Solomons over China pac...| [neutral]|\n",
            "|      positive|RYU Apparel Brings Customer Care Services In-ho...|[positive]|\n",
            "|      negative|Odisha Dalit man made to rub nose in own spit f...|[negative]|\n",
            "|       neutral|Man United hire Erik ten Hag as 5th manager in ...|[positive]|\n",
            "|      negative|Teddy Bear, the North Myrtle Beach Humane Socie...|[positive]|\n",
            "|      positive|Pembroke Castle Goodwick among stunning camera ...| [neutral]|\n",
            "|      negative|South Africa launches relief for Durban floodin...|[negative]|\n",
            "|      negative|Concerns mount as ‘extremely infectious’ avian ...|[positive]|\n",
            "|       neutral|Scientists analyse ‘speech’ of elusive Scottish...| [neutral]|\n",
            "|      negative|VLTA LAWSUIT ALERT: Levi & Korsinsky Notifies V...|[positive]|\n",
            "|      positive|Alaska Air Group Inc. Q1 Loss Decreases, beats ...|[positive]|\n",
            "|       neutral|‘My body is here, but my soul, mind and everyth...| [neutral]|\n",
            "|      negative|In a veiled attack, Imran Khan blames Pak Army ...|[positive]|\n",
            "|       neutral|Sigma Planning Corp Buys Shares of 1,637 Jazz P...| [neutral]|\n",
            "|       neutral|CGI to release second quarter fiscal 2022 resul...|[positive]|\n",
            "|       neutral|What You Need To Know About The Inaugural Santa...| [neutral]|\n",
            "|       neutral|Tech-infused Lake Nona Wave Hotel guest rooms f...|[positive]|\n",
            "|       neutral|Vertex Pharmaceuticals Incorporated (NASDAQ:VRT...| [neutral]|\n",
            "|      positive|India adds 13.5 GW of renewable capacity in FY2...|[positive]|\n",
            "+--------------+--------------------------------------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds.select('True_Sentiment','text',\"class.result\").show(50, truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8-JF5_Y9uPFj"
      },
      "outputs": [],
      "source": [
        "preds_df = preds.select('True_Sentiment','text',\"class.result\").toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "CS2q_OajuZyO"
      },
      "outputs": [],
      "source": [
        "# The result is an array since in Spark NLP you can have multiple sentences.\n",
        "# This means you can add SentenceDetector in the pipeline and feed it into\n",
        "# UniversalSentenceEncoder and you can have prediction based on each sentence.\n",
        "# Let's explode the array and get the item(s) inside of result column out\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "naAHGWV5ugNX"
      },
      "outputs": [],
      "source": [
        "# We are going to use sklearn to evalute the results on test dataset\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2BiHF_sR3Cz"
      },
      "source": [
        "Let's use `classification_report` from `sklearn` to evaluate the final scores. (keep in mind due to limited resources on a free Google Colab we only used 5 Epochs :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLeO9u1bunPB",
        "outputId": "46db3dda-4c74-432a-b765-150b31dcadf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.33      0.47        12\n",
            "     neutral       0.73      0.57      0.64        14\n",
            "    positive       0.42      0.89      0.57         9\n",
            "\n",
            "    accuracy                           0.57        35\n",
            "   macro avg       0.65      0.60      0.56        35\n",
            "weighted avg       0.67      0.57      0.56        35\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (classification_report(preds_df['True_Sentiment'], preds_df['result'] ))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Train_sentiment_classifier_with_our_data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nteract": {
      "version": "0.21.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}